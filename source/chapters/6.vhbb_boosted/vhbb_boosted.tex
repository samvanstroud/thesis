\chapter{Boosted VHbb Analysis}\label{chap:vhbb_boosted}

The Higgs boson, first observed by \ATLAS and \CMS at the LHC in 2012 \cite{HIGG-2012-27,CMS-HIG-12-028}, is predicted by the standard model to decay primarily to a pair of \bquarks, with a branching factor of $0.582 \pm 0.007$ for $m_H = \SI{125}{\GeV}$ \cite{deFlorian:2016spz}. 
Observation of this decay mode was reported by \ATLAS \cite{HIGG-2018-04} and \CMS \cite{CMS-HIG-18-016} in 2018, establishing the first direct evidence for the Yukawa coupling of the Higgs boson to down-type quarks (see \cref{sec:higgs_yukawa_coupling}).
The \Hbb process is also important for constraining the total decay width of the Higgs \cite{Lafaye:2009vr}.

Whilst the dominant Higgs production mechanism at the LHC is gluon-gluon fusion as outlined in \cref{sec:higgs_pheno}, this mechanism has an overwhelming QCD multijet background and so overall sensitivity to the Higgs is low.
The QCD multijet background refers to events containing one or more strongly produced jets which are not the decay product of heavy resonances, for example $g \to q\bar{q}$.
The gluon-gluon fusion channel contains to leading order only jets in the final state, and therefore it is extremely difficult to distinguish signal events from the overwhelming multijet background.
The \hbb observation therefore searched for Higgs bosons produced in association with a vector boson $V$ (where $V$ can be a \Wboson or \Zboson boson) which subsequently decays leptonically.
The leptonic final states from the decay of the vector boson allow for leptonic triggering whilst at the same time significantly reducing the multijet background.

A closely related analysis \cite{HIGG-2018-52} has more recently measured the associated production of a Higgs boson decaying to \bquarks in events where the vector and Higgs bosons are highly boosted.
The analysis is outlined in \cref{sec:vhbb_overview}.
Modelling studies performed by the author are detailed in \cref{sec:vhbb_modelling}, and the results of the analysis are presented in \cref{sec:vhbb_results}.
The author contributed to various signal and background modelling studies, fit studies, and to the diboson unblinding effort.
This analysis has been published in \rcite{HIGG-2018-52}.
Figures and tables from \rcite{HIGG-2018-52} are reproduced here.

\section{Analysis Overview}\label{sec:vhbb_overview}

The boosted \VHbb analysis is focused on the high transverse momentum regime, which has the benefit of being more sensitive to physics beyond the Standard Model \cite{Mimasu:2015nqa}, but the disadvantage of being more challenging due to the increased difficulty in the accurate reconstructed of highly energy events (discussed in \cref{chap:tracking}).
In order to focus on the \highpt regime, the reconstructed vector boson is required to have $\ptv > \SI{250}{\GeV}$(see \cref{sec:vhbb_object_reco}).
Events are also split into two \ptv bins with the first bin covering $\SI{250}{\GeV} < \ptv < \SI{400}{\GeV}$ and the second covering $\ptv > \SI{400}{\GeV}$, which allows the analysis to account for the improved signal-to-background in the \highpt regime.

The previous \ATLAS analysis in \rcite{HIGG-2018-04} was primarily sensitive to vector bosons with a more modest \ptv boost in the region of 100--\SI{300}{\GeV}.
In this regime, the Higgs candidate was reconstructed using a pair of jets with radius parameter of $R = 0.4$, called \smallR jets.
However in the \highpt regime, the decay products of the Higgs boson become increasingly collimated and the \smallR jets may overlap.
In order to avoid the associated problems and to aid in the reconstruction of the Higgs boson candidate, the present analysis uses instead a \largeR jet with radius parameter $R = 1.0$ to reconstruct the Higgs boson candidate in all channels (see \cref{sec:jet_reco}).
The Higgs candidate is required to have exactly two ghost-assciated and \btagged variable-radius track-jets.
The candidate \largeR jet is reconstructed using jet substructure techniques, for example it is trimmed by removing soft and wide-angle components, which helps to remove particles from the underlying event and pileup collisions \cite{PERF-2012-02}.
Refer to \cref{sec:jet_reco} for more details on jet reconstruction.

On top of the binning in \ptv, selected events are further categorised into 0-, 1- and 2-lepton channels depending on the number of selected charged leptons (electrons and muons) are present in the reconstructed final state (also referred to as 0L, 1L, and 2L respectively).
The 0-lepton channel targets the $\Zboson \higgs \rightarrow \nu\nu \bbbar$ process, the 1-lepton channel targets $\Wboson \higgs \rightarrow \ell\nu \bbbar$, and the 2-lepton channel targets $\Zboson \higgs \rightarrow \ell\ell \bbbar$, where $\ell$ is an electron or muon and $\nu$ is a neutrino.
Each channel has a dedicated set of selections which are listed in more detail in \cref{sec:vhbb_selections}.
Events in the 0- and 1-lepton channels are further split depending on the number of additional \smallR jets
not matched to the Higgs-jet candidate.
The high-purity signal region (HP SR) has zero such jets, while the low-purity signal region (LP SR) has one or more.
%The 0- and 1-lepton channels are split into high- and low-purity signal regions based on the number of additional untagged \smallR jets present in the event.
The 0- and 1-lepton channels also make use of a dedicated \ttbar control region, described in \cref{sec:vhbb_control_region}.
An complete overview of the different analysis regions is given in \cref{tab:SR_CR_definition}.

%
\input{chapters/6.vhbb_boosted/tables/regions.tex}
%


\subsection{Data \& Simulated Samples}\label{sec:vhbb_samples}

The analysis uses \pp\ collision data recorded between 2015 and
2018 by the ATLAS detector~\cite{PERF-2007-01} during Run~2 at the
LHC. This dataset corresponds to an integrated luminosity
of \intlumi.

Data from centre-of-mass energy \come{13} proton-proton collisions at the \LHC recorded over the course of \runtwo were used for the analysis.
The resulting dataset corresponds to a total integrated luminosity of \intlumi (see \cref{fig:run2_lumi}).

An overview of the MC simulated samples used in the analysis is given in \cref{tab:vhbb_samples}.
These samples are used to model the signal and background processes relevant to the analysis, with the exception of teh multijet background which is modelled using a data-driven technique.
Data and simulated events are reconstructed using the same algorithms, and a reweighting is applied to the simulated events in order to match the pile-up distribution
observed in the data.
%
\input{chapters/6.vhbb_boosted/tables/mc_samples.tex}
%

\subsection{Object Reconstruction}\label{sec:vhbb_object_reco}

The presence of neutrinos in the $\Wboson \higgs \rightarrow \ell\nu \bbbar$ and $\Zboson \higgs \rightarrow \ell\ell \bbbar$ signatures can be inferred from a momentum imbalance in the transverse plane \cref{sec:missing_Et}.
The vector boson transverse momentum \ptv is reconstructed as the missing transverse energy \ETmiss in the 0-lepton channel, as the magnitude of the summed \vETmiss and charged-lepton momentum in the 1-lepton channel, and as the transverse momentum of the 2-lepton system in the 2-lepton channel (see \cref{sec:missing_Et}).

Leptons are used for the channel classification and to select relevant events as outlined in \cref{sec:vhbb_selections}.
Electrons and muons are reconstructed as outlined in \cref{sec:lepton_reco}.
Electron identification follows the approach outlined in \rcite{HIGG-2018-04}.
In addition to the likelihood-based method described in \cref{sec:lepton_reco}, \textit{baseline} electrons are required to satisfy $\pt > \SI{7}{\GeV}$, $|\eta| < 2.47$, $\dzerosig < 5$, and $|\zzsth|< \SI{0.5}{\milli\meter}$.
\textit{Signal} electron additionally are required to satisfy a tighter likelihood identification selection.
Muons are required to satisfy $\pt > \SI{7}{\GeV}$, $|\eta| < 2.7$, $\dzerosig < 3$, and $|\zzsth|< \SI{0.5}{\milli\meter}$.
\textit{Baseline} muons are required to pass the `loose' identification described in \rcite{PERF-2015-10}, while \textit{signal} muons are required to pass the `medium' identification working point.
All signal leptons are required to additionally satisfy a $\pt > \SI{27}{\GeV}$ selection criteria, except for muons in the 1-lepton channel where a cut of \SI{25}{\GeV} is used.
The number of baseline leptons is used to categorise the event into the 0-, 1- or 2-lepton channels.
The 1- and 2-lepton channels additionally require one signal lepton to be present.

The track-jets matched to the Higgs candidate are \btagged using the MV2c10 \btagging algorithm \cite{ATL-PHYS-PUB-2015-022,FTAG-2018-01,ATL-PHYS-PUB-2017-013}.
MV2c10 is a machine learning algorithm using a Boosted Decision Tree (BDT) which is tuned to achieve an average \bjet efficiency of \pct{70} on simulated \ttbar events.
At this efficiency working point, rejection factors for \cjets and \ljets are approximately 9 and 304 respectively.
The MV2 algorithm takes inputs from the outputs of a number of low-level algorithms (IPxD, SV1 and JetFitter).
The outputs of the low-level algorithms are provided as inputs to the boosted decision tree.
The efficiency of the tagging algorithm is calibrated to events in data \cite{PERF-2016-05,ATLAS-CONF-2018-006,ATLAS-CONF-2018-001}.
The jet tagging strategy relies on extensive studies into track-jet \btagging in boosted topologies \cite{ATL-PHYS-PUB-2014-013, PERF-2017-04}.

The jet flavour labelling scheme is described in \cref{sec:jet_reco}.


\subsection{Selection Criteria}\label{sec:vhbb_selections}

An extensive list of selection cuts are applied to each event in order to reject background events whilst retaining as many signal events as possible. 
A full list of selection cuts applied to the different analysis regions is given in \cref{tab:vhbb_selection}, while some key selections are listed below.

All channels are require events with at least one \largeR jet with $\pt > \SI{250}{\GeV}$ and $|\eta| < 2.0$.
The vector boson transverse momentum is also required to satisfy $\ptv > \SI{250}{\GeV}$.
The Higgs candidate is chosen as the highest \pt \largeR jet satisfying these requirements.
As mentioned, the candidate \largeR jet is required to have two ghost-assciated and \btagged variable-radius track-jets.
These track-jets are required to have at least two constituent tracks with $\pt > \SI{500}{\MeV}$ and $|\eta| < 2.5$.
The track-jets themselves must satisfy $\pt > \SI{10}{\GeV}$ and $|\eta| < 2.5$.

In the 0-lepton channel, trigger selections are applied using an \ETmiss trigger with a luminosity-dependent threshold between 70--\SI{110}{\GeV}.
In the 1-lepton electron sub-channel a combination of single electron triggers is used with minimum \pt thresholds between 24--\SI{26}{\GeV}.
In the muon sub-channel the same \ETmiss trigger as the 0-lepton channel is used.
Since muons are not used for the \ETmiss trigger calculations, this is in effect a \pt requirement on the muon-neutrino system, which in the analysis phase space is more efficient than a single-muon trigger.
The 2-lepton channel uses the same triggering strategy as the 1-lepton channel.
In all channels, the trigger selections applied are fully efficient for events selected using the full requirements in \cref{tab:vhbb_selection}.

The combined selections in \cref{tab:vhbb_selection} result in a signal efficiency ranging from 6--\pct{16} for the $\Wboson\higgs$ and $\Zboson\higgs$ processes depending on the channel and \ptv bin.

%
\input{chapters/6.vhbb_boosted/tables/event_selection.tex}
%

\subsection{Control Region}\label{sec:vhbb_control_region}

The \ttbar process presents a major background in the 0- and 1-lepton channels.\todo{not sure where the 0L ttbar ETmiss comes from}
In these events, the Higgs candidate is often reconstructed from a correctly tagged \bjet from the top decay $t \to \Wboson b$, and an incorrectly tagged $c$- or \ljet from the subsequent decay of the \Wboson, as shown in \cref{fig:sr_cr_diagrams}.

The only known decay mode of the top quark is via the weak force to a \Wboson and a down-type quark. (it is the only quark heavy enough to decay into an on-shell \Wboson).
Overwhelmingly (\pct{96} of the time) the down-type quark is a \bquark
Hence, the second top quark is also likely to result in a second tagged \btagged track-jet outside of the \largeR Higgs candidate.
To ensure sufficient \ttbar rejections, 0- and 1-lepton channel signal regions are defined using a veto on events with \btagged track-jets outside the Higgs-jet candidate.
These events are used to construct a control region (CR) which is enriched in \ttbar events.
The CR is used to constrain the normalisation of the \ttbar background in the fit.

%
\begin{figure}[!htbp]
  \centering
  \includegraphics[width=0.65\textwidth]{chapters/6.vhbb_boosted/figs/sr_cr_diagrams.pdf}
  \caption{
    Diagrams or the signal process (top) and the 0-lepton and 1-lepton \ttbar backgrounds (middle, bottom).
    Object to the right of centre are reconstructed within the \largeR jet.
    For the backgrounds, the \largeR jet contains a mis-tagged $c$- or \ljet.
  }
  \label{fig:sr_cr_diagrams}
\end{figure}
%

\subsection{Background Composition}\label{sec:vebb_background_composition}

After the selections described in \cref{sec:vhbb_selections} the number of background events mimicking the \VHbb signal is greatly reduced.
However, the number of background events still greatly outnumbers that of signal events.
The background processes are channel dependent.
In the 0-lepton channel the dominant sources of backgrounds are \Zjets ($\Zboson \to \nu\nu$) and \ttbar, with \Wjets and diboson events being subdominant.
In the event of $\Wboson \to \tau\nu$, and subsequent hadronic decay of the $\tau$ or lack of successful reconstruction/selection of the leptonic decay products, \Wjets can also contribute to the 0-lepton channel.
\ttbar and \Wjets (with a leptonic decay of the \Wboson as in $\Wboson \to \ell\nu$) are dominant in the 1-lepton channel, while single-top is subdominant.
In the 2-lepton channel, \Zjets ($\Zboson \to \ell\ell$) is again dominant followed by \Zboson\Zboson diboson events.

The diboson background $VV$ consists primarily of \Wboson\Zboson and \Zboson\Zboson events in which the \Zboson decays to a pair of \bquarks.
This process very closely matches the signal, with a resonant peak occurring at $m_Z = \SI{91}{\GeV}$ and so is considered as an 
irreducible background ($V$+\bjets is also irreducible).

The $t\overline{t} V$, $t\overline{t} H$ and multijet backgrounds are negligible in the analysis phase space after the selections have been applied, with the exception of the 1-lepton electron sub-channel, in which multijet background is not ignored.
The multijet background is made up of jets with semileptonic heavy-flavour-hadron decays (e.g. $b \to c \ell \nu$) and jets which are mis-tagged by the flavour tagging algorithm MV2c10.

The contributions from the different backgrounds are modelled using Monte Carlo event generators and the impacts on the analysis are studied in \cref{sec:vhbb_modelling}.
The multijet background is not modelled but instead estimated using a data-driven technique.


\section{Systematic Uncertainties \& Background Modelling}\label{sec:vhbb_modelling}
% modelling note \cite{Bell:2316951}

Systemic uncertainties are extensively employed to give the fit model described in \cref{sec:vhbb_fit} enough flexibility to account for inaccuracies in the various inputs to the fit.
Two main types of systematic uncertainty are considered: experimental and modelling.
%Theoretical uncertainties arise due to imperfect precision used in e.g. QCD calculations.
Experimental uncertainties arise due to the limited due to limited detector precision, imperfect reconstruction algorithms (in particular the \btagging algorithms), and due to the imperfect measurement of pile-up and integrated luminosity.
Modelling is the simulation processes relevant to the analysis using Monte-Carlo (MC) event generators, and is used to predict the outcome of the analysis.
Modelling uncertainties arise due to the imperfections in the simulation of signal and background events, for example differences between event generators, or use of different model parameters when producing simulated events.
In order to observe a certain process, for example \VHbb, an increase in the number of observed events with respect to the background-only hypothesis is looked for.
The excess is often relatively small against the total number of background events, and hence accurate modelling of the expected number of background and signal events is crucial for successfully performing the analysis.
Particular care is paid to the uncertainties on the modelling predictions as discussed in this section.

Modelling uncertainties are described in detail in the following sections.
Modelling uncertainties:
\textit{Nominal} samples are are used as a reference to which different variations can be compared.
The nominal samples are chosen as the best possible representation of the underlying physical process.
\textit{Alternative} samples are used to understand inaccuracies that may be present in the nominal samples.
Some aspect of the nominal model is varied, and the discrepancy with respect to the nominal model is quantified.
The discrepancy is used to systematic uncertainty associated with the model parameter which was changed.

Modelling studies involving $c$- and \ljets is hampered by the low available statistics of jets pass the analysis selections, due to the high rejection rates of the \btagging algorithm MV2c10.
For modelling studies therefore, truth tagging (TT) is employed to ensure sufficient numbers of jets are available to calculate uncertainties.
TT works by computing a 2-dimensional efficiency map using the jet \pt and jet $\eta$.
The two leading track-jets associated to the \largeR jet automatically passes the \btagging requirement, and are weighted based on their \pt and $\eta$ using the pre-calculated efficiency map.


\subsection{Sources of Systematic Uncertainties}\label{sec:sources_of_uncertainties}

This section briefly describes the different sources of uncertainty in the predictive model used in the analysis, and how each source of uncertainty is implemented within the analysis framework.
Considered sources of systematic uncertainty are listed in \cref{tab:sources_of_uncertainty}.
For each source of uncertainty, acceptance and shape uncertainties are derived.

\subsubsection{QCD Scales}
\begin{comment}
Perturbative QCD predictions for inelastic pp scattering depend on two scales that arise
when dealing with UV and IR divergencies: renormalization scale Î¼R and factorization scale Î¼F
The choice of these scales is arbitrary, to get a feeling for the dependence, the scales are
by convention varied usually by a factor 2 in both directions
\end{comment}
The \Vjets matrix element calculations contains infrared and ultraviolet divergences.
These are handled by introducing spurious parameters corresponding to the renomalisation scale ($\mu_R$) and factorisation scale ($\mu_F$).
Physical observables are not dependent on these parameters when using the infinite perturbation series expansion, however at some fixed order in QCD a limited dependence is present.
To assess the impact of this, both $\mu_R$ and $\mu_F$ are independently varied from their nominal values by factors of $0.5$ and $2$ to account for higher order corrections to the calculation of the matrix element used to simulate the process.

\subsubsection{PDF Sets}

Parton distribution functions (PDFs) specify the probability of finding a parton with a given momentum inside a hadron (in this case, inside colliding protons).
PDFs have to be derived from data and are a significant source of uncertainty in analyses of hadronic collision data.
There are three sources of PDF uncertainties: the statistical and systematic errors on the underlying data used to derive the PDFs, the theory which is used to describe them (which is based on some fixed order perturbative QCD expansion), and finally the procedure which is used to extract the PDFs from the data. 
PDF-related uncertainties were derived following \rcite{Butterworth:2015oua}.
This involves considering 100 PDF replicas which, when combined, form a central value and associated uncertainty, and also in parallel direct changes to the central values of PDFs using the MMHT2014 \cite{Harland-Lang:2014zoa} and CT14NLO \cite{Dulat:2015mca} PDF sets.

\subsubsection{Event Generator}

The choice of parton shower (PS) and underlying event (UE) generators can affect the analysis outcome.
Changing these models modifies several aspects of the event generation at the same time, such as the accuracy of matrix element predictions and different approaches to parton showering.
This change tends to lead to the largest disrepancy with respect to the nominal samples.

\subsubsection{Resummation and Merging Scales}

Resummation is a technique used in QCD to help cope with calculations involving disparate energy scales, and involves the introduction of an associated resummation scale, the choice of which introduces some systematic uncertainty into the model.
Parton showering models are accurate when simulating \lowpt radiation, however inaccuracies start to arrive when simulating hard emissions.
To combat this, parton showering models utilise more precise matrix element calculations above some momentum threshold.
The choice of threshold, or \textit{merging scale} introduces some uncertainty into the final result.
Resummation (QSF) and merging (CKKW) scale variations are available for a subset of the \textsc{Sherpa} samples.
The number of available events is significantly lower than the number of events in the nominal sample, and no statistically significant discrepancy with respect to the nominal samples is observed.
The corresponding uncertainties and therefore neglected.

\subsection{Implementation of Variations}\label{sec:implementation_of_variations}

Modelling variations are implemented in different ways, depending on the associated uncertainty.\cref{tab:sources_of_uncertainty} lists the different sources of uncertainty described in \cref{sec:sources_of_uncertainties} and for each lists the implementation.
%
\input{chapters/6.vhbb_boosted/tables/sources_of_uncertainty.tex}
%
As production of high-stastic MC samples is computationally expensive, a technique in state of the art simulation packages is to store some sources of variation as internal weights, which can be generated alongside the nominal samples, saving computation time.
The nominal sample then effectively contains information about an ensemble of different samples, corresponding to different model parameters, which are accessible via reweightings. 
When filling histograms for the variations, bins are incremented by the internal weight of the event associated with the variation in question.

While the inclusion of internal weight variation in MC event generators has decreased simulation times and increased available statistics, there are in \textsc{Sherpa 2.2.1} currently some sources of systematic uncertainty that are unable to be stored as internal weight variations due to technical limitations.
Two examples are the choice of resummation and merging scales.
A method to parameterise the systematic variation using one sample, and to then apply this parameterisation to another sample, has been developed by \ATLAS \cite{Anders:2125718}.
This method was used to derive resummation and merging uncertainties for the nominal \textsc{Sherpa 2.2.1} sample, using a previous (lower statistic) \textsc{Sherpa 2.1} alternative sample.
The resulting uncertainties were studied and found to be negligible in comparison with systematics from other sources.

\subsection{Vector Boson + Jets Modelling}

After event selection, the \Vjets background is a dominant background in all three analysis channels as described in \cref{sec:vebb_background_composition}.
The \Vjets samples are split into categories depending on the truth flavour of the track-jets which are ghost-associated to the \largeR jet Higgs candidate.
The categories are $V$+$bb$, $V$+$bc$, $V$+$bl$, $V$+$cc$, $V$+$cl$, $V$+$ll$, and $V$+hf refers collectively to the categories containing at least one $b$- or \cjet.
$V$+$bb$ is dominant generally accounting for \pct{80} of the jets, while $V$+hf accounts for around \pct{90} of jets.
The full flavour composition breakdown for each channel and analaysis region are given in \cref{tab:Wjets_0L_flavcomp,tab:Wjets_0L_flavcomp,tab:Zjets_0L_flavcomp,tab:Zjets_2L_flavcomp}.

In order to access uncertainties associated with the use of MC generators, variations of the data are produced using alternative generators or variation of nominal generator parameters as described in \cref{sec:implementation_of_variations}.
As described in \cref{sec:vhbb_samples}, the nominal MC event generator used for \Vjets events is \textsc{Sherpa 2.2.1}, while \textsc{MadGraph5\_aMC@NLO+Pythia8} (which uses a different parton showering model) is used as an alternative generator.

Modelling systematics can have several impacts, including affecting the overall normalisation for different processes, and the relative acceptances between different analysis regions (i.e. migrations between HP and LP SRs, between the SR and CR, and between \pTV bins), and the shapes of the $m_J$ distributions.
Since the fit model fits only the \largeR jet mass $m_J$ to data, all shape uncertainties are estimated with respect to this observable.
Several sources of uncertainty, summarised in \cref{sec:sources_of_uncertainties}, have been assessed.

\input{chapters/6.vhbb_boosted/tables/Wjets_0L_flavcomp.tex}
\input{chapters/6.vhbb_boosted/tables/Wjets_1L_flavcomp.tex}
\input{chapters/6.vhbb_boosted/tables/Zjets_0L_flavcomp.tex}
\input{chapters/6.vhbb_boosted/tables/Zjets_2L_flavcomp.tex}



\subsubsection{Acceptance Uncertainties}

Several different types of acceptance uncertainties have been calculated and implemented as nuisance parameters in the fit.
These account for uncertainty in the overall number of events in each channel, and for the migration of events between different analysis regions.
The acceptance uncertainties relevant to the \Vjets processes are summarised below.
%
\begin{itemize}
    \item \textbf{Overall normalisation:} only relevant where normalisation cannot be left floating (determined as part of the fit). The $V$+hf component is left floating in the fit. For other components, independent normalisations used for $W$+hf and $Z$+hf. The contributions are mainly determined by the 1-lepton (for $W$+hf) and 2-lepton (for $Z$+hf) SRs respectively and then extrapolated to 0-lepton channel.
    %
    \item \textbf{SR-to-CR relative acceptance:} the uncertainty on the normalisation of the signal region due to events migrating between the signal and control regions.
    %
    \item \textbf{HP-to-LP relative acceptance:} the uncertainty on the normalisation of the high-purity (HP) signal region due to events migrating between the high- and low-purity signal regions.
    %
    \item \textbf{Medium-to-high} \pTV \textbf{relative acceptance:} describes any shape effect in \pTV distribution, given that the analysis only uses two \pTV bins (medium and high).
    %
    \item \textbf{Flavour relative acceptance:} for each flavour $V$+$xx$, where $xx\in$ \{$bc$,$bl$,$cc$\} the ratio of $V$+$xx$/$V$+$bb$ events is calculated. This corresponds to the uncertainty of $Vbb$ events due to the miss-tagging of other flavours V$xx$.
    %variations in the ð‘‰ + ð‘ð‘/ð‘‰ + ð‘ð‘, ð‘‰ + ð‘ð‘™/ð‘‰ + ð‘ð‘ and ð‘‰ + ð‘ð‘/ð‘‰ + ð‘ð‘ ratios are accounte for independently for the ð‘Š- and ð‘-boson backgrounds.
\end{itemize}
%
The uncertainties arising from the different sources described in \cref{sec:sources_of_uncertainties} are summed in quadrature to give a total uncertainty on each region.
A summary of the different acceptance uncertainties that were derived in this way and subsequently applied in the fit are given in \cref{tab:Vjets acceptance uncerts}.
An effort has been made, wherever possible, to harmonise similar uncertainties across different analysis regions and channels.

\input{chapters/6.vhbb_boosted/tables/V+jets-acceptance-uncertainties-summary.tex}

\subsubsection{Shape Uncertainties}

In order to derive shape uncertainties (which as the name suggests affect shapes but not overall normalisations of distributions), the following procedure is carried out.
Normalised distributions of the reconstructed \largeR Higgs candidate jet mass $m_J$ are compared for the nominal sample and variations.
For each variation, the ratio of the variation to nominal is calculated, and an analytic function is fit to the ratio.
If different analysis regions or channels show the same pattern of variation, a common uncertainty is assigned.
An example of a significant source of uncertainty, arising from choice of factorisation scale $\mu_R$ is shown in \cref{fig:Vjets_SysMUR}.
HP SRs split into medium and high \pTV bins are shown for the 0-lepton channel for \Whf and \Zhf jets.
The 0- and 1-lepton channels for the \Whf contribution and the 0- and 2-lepton channels for the \Zjets contribution are merged, since the shapes in $m_J$ are consistent across channels.
An exponential function $e^{p_0+p_1x}+p_2$ has been fitted to the ratio of the normalised distributions.
The magnitude of the variation does show \ptv dependence, and so two separate uncertainties are added in the fit, and applied individually in each \pTV region. 
%
\begin{figure}[!htbp]
  \centering
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/0L_Whf_2tag1pfat0jet_250_400ptv_SR_noaddbjetsr_mJIncl_SysMUR.pdf}
    \caption{\Whf, HP SR, medium \pTV}
    \label{fig:Vjets_SysMUR_sub1}
  \end{subfigure}%
  \hfill
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/0L_Whf_2tag1pfat0jet_400ptv_SR_noaddbjetsr_mJIncl_SysMUR.pdf}
    \caption{\Whf, HP SR, high \pTV}
    \label{fig:Vjets_SysMUR_sub2}
  \end{subfigure}
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/0L_Zhf_2tag1pfat0jet_250_400ptv_SR_noaddbjetsr_mJIncl_SysMUR.pdf}
    \caption{\Zhf, HP SR, medium \pTV}
    \label{fig:Vjets_SysMUR_sub3}
  \end{subfigure}%
  \hfill
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/0L_Zhf_2tag1pfat0jet_400ptv_SR_noaddbjetsr_mJIncl_SysMUR.pdf}
    \caption{\Zhf, HP SR, medium  \pTV}
    \label{fig:Vjets_SysMUR_sub4}
  \end{subfigure}%
  \hfill
  \caption{Normalised leading \largeR jet mass distribution from \Zboson and \Whf processes in the HP SR of the \zlep channel. The renormalisation scale $\mu_r$ has been varied by a factor of 2 (1up) and 0.5 (1down). An exponential function is fitted to the ratio between the nominal and variation samples.}
  \label{fig:Vjets_SysMUR}
\end{figure}

The impacts of variations in the factorisation scale $\mu_{F}$ and the choice of PDF set on \mJ shape were found to be negligible in comparison with $\mu_{R}$ and are hence ignored.

The shape uncertainties derived on the SRs are also applied to the CRs, as the low statistics in the CRs make it difficult to derive dedicated shape uncertainties.
All the shape uncertainties are fully correlated accross regions.

%and the UP and DOWN are considered as symmetric variations.


A comparison of the \mJ shapes between \SHERPA and \MADGRAPH is shown in \cref{fig:Vjets_MGSherpa_inc}.
The plots are split by process and channel, but merged in SR purity and \ptv bins reflecting similarities between the \mJ shapes across these regions.
Due to the low statistics available for the alternate \MADGRAPH sample, and the lack of statistically significant variation between the samples, no associated shape uncertainty is added to the fit in this case. 

\begin{figure}[!htbp]
  \centering
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/0L_Whf_2tag1pfat0pjet_ptvinc_SR_noaddbjetsr_mJIncl.pdf}
    \caption{\Whf, \pTV inclusive SR, \zlep channel}
    \label{fig:Vjets_MGSherpa_inc_sub1}
  \end{subfigure}%
  \hfill
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/1L_Whf_2tag1pfat0pjet_ptvinc_SR_noaddbjetsr_mJIncl.pdf}
    \caption{\Whf, \pTV inclusive SR, \olep channel}
    \label{fig:Vjets_MGSherpa_inc_sub2}
  \end{subfigure}
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/0L_Zhf_2tag1pfat0pjet_ptvinc_SR_noaddbjetsr_mJIncl.pdf}
    \caption{\Zhf, \pTV inclusive SR, \zlep channel}
    \label{fig:Vjets_MGSherpa_inc_sub3}
  \end{subfigure}%
  \hfill
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/2L_Zhf_2tag1pfat0pjet_ptvinc_SR_mJIncl.pdf}
    \caption{\Zhf, \pTV inclusive SR, \tlep channel}
    \label{fig:Vjets_MGSherpa_inc_sub4}
  \end{subfigure}%
  \hfill
  \caption{The comparison on \mJ shapes between \SHERPA and \MADGRAPH samples
  from \Vhf process in \pTV inclusive signal regions.
  The Kolmogorov-Smirnov test and $\chi^2/ndf$ are shown on the plots.}
  \label{fig:Vjets_MGSherpa_inc}
\end{figure}


\subsection{Diboson Modelling}

The uncertainties for the diboson background generallys follows that of \Vjets.
However an alternative sample was generated using \textsc{Powheg} interfaced with \textsc{Pythia8}, using the AZNLO shower tune with the CTEQ6L1 PDFs \cite{Pumplin:2002:CTEQ6L1}.
Unlike \textsc{Sherpa}, \textsc{Powheg} models the off-shell $Z$ contribution at NLO.

Acceptance and shape uncertainties are derived in an analagous fashion to \Vjets.

\subsubsection{Acceptance Uncertainties}

Diboson acceptance uncertainties are summarised in \cref{tab:diboson_acceptance_uncerts}.

\input{chapters/6.vhbb_boosted/tables/VV_acceptance_uncertainties.tex}

\subsubsection{Shape Uncertainties}

textsc


\section{Fit Model}\label{sec:vhbb_fit}



\begin{comment}
  All initial background distribution shapes prior to the fit (described in Section 8), except those for multÄ³et, are estimated from the samples of simulated events. The multÄ³et shape and normalisation are determined using data
  \end{comment}

\begin{comment}
  The normalisation on the diboson background is left floating in the fit, i.e. measured simulatneously along with the $VH$ signal


  In the statistical analysis described in Section 8, the components ð‘Š/ð‘ + ð‘ð‘, ð‘Š/ð‘ + ð‘ð‘, ð‘Š/ð‘ + ð‘ð‘™ and
ð‘Š/ð‘ + ð‘ð‘ are treated as a single background component denoted by ð‘Š/ð‘+HF. The ð‘Š+HF and ð‘+HF
contributions, which together constitute 90% of ð‘‰+jets background, are estimated separately, each with its
own normalisation factor determined from the fit to data
\end{comment}

%The \HiggsJet\ mass candidate in the different signal
%regions are used as the discriminant variable and are combined using a
%binned maximum-likelihood fit, referred to as the global likelihood
%fit, which allows the signal yield and the background normalisations
%to be extracted.

%The signal is extracted from a combined profile likelihood fit to the \largeR jet mass, using several signal and control regions. The yield of diboson production $VZ$ with $Z \rightarrow b\bar{b}$ is also measured using the same fit and provides a validation of the analysis. The cross-section measurements are performed within the simplified template cross-section (STXS) framework~\cite{deFlorian:2016spz, Badger:2016bpw}. These measurements are then used to constrain anomalous couplings in a Standard Model effective field theory (SMEFT)~\cite{Contino:2013kra}.

A global profile likelihood fit is used to extract the signal strength $\mu$ and its significance from the data. This statistical setup treats each bin as a Poisson counting experiment. The combined likelihood over $N$ bins, without considering sources of systematic uncertainty, is given by
%
\begin{equation}
    \mathcal{L}(\mu) = \prod_{i=1}^N \frac{(\mu s_i + b_i)^{n_i}}{n_i!} \exp \left[ - (\mu s_i + b_i) \right],
\end{equation}
%
where $s_i$ ($b_i$) is the expected number of signal (background) events in bin $i$, and $n_i$ is the number of events observed in data in bin $i$. The presence of systematic uncertainties which can affect the expected numbers of signal and background events necessitates the addition of nuisance parameters (NPs), $\theta$, to the likelihood. Each source of systematic uncertainty for \Vjets samples discussed in the previous section was implemented as a NP $\theta_j$ in the fit. The presence of NPs modifies the likelihood as 
%
\begin{equation}
    \mathcal{L}(\mu) \rightarrow \mathcal{L}(\mu, \theta) = \mathcal{L}(\mu) \times \mathcal{L}(\theta) , \quad s_i \rightarrow s_i(\theta) , \quad b_i \rightarrow b_i(\theta),
\end{equation}
%
where
%
\begin{equation}
    \mathcal{L}(\theta) = \prod_{\theta_j \in \theta} \frac{\exp\left[{-\theta_j^2/2}\right]}{\sqrt{2\pi}}.
\end{equation}
%


Statstical uncertainty is also present.

\section{Results}\label{sec:vhbb_results}

\begin{comment}
  paper abstract
  The measured
  signal strength, defined as the ratio of the measured signal yield to
  that predicted by the Standard Model, is $0.72 ^{+0.39}_{-0.36}$
  corresponding to an observed (expected) significance of 2.1 (2.7)
  standard deviations. Cross-sections of associated production of a
  Higgs boson decaying into $b$ quark pairs with a \Wboson or \Zboson gauge
  boson, decaying into leptons, are measured in two exclusive
  vector boson transverse momentum regions, 250--\SI{400}{\GeV} and above \SI{400}{\GeV}, and
  interpreted as constraints on anomalous couplings in the framework of
  a Standard Model effective field theory.

  %For a Higgs boson mass of \SI{125}{\GeV}, an excess of events over the expected background from other Standard Model processes is found
  %with an observed significance of $3.5$ standard deviations, compared to an expectation of $3.0$
  %standard deviations. This excess provides evidence for the Higgs boson decay into b-quarks
  %and for its production in association with a vector boson. Assuming the Standard Model production 0.19
  %cross-section, the results are consistent with the value of the Yukawa coupling to b-quarks in the Standard Model.
\end{comment}

\subsection{Pre-fit Yields}


\subsection{Post-fit Results}

Post-fit $m_J$ distributions in the high-purity medium \pTV regions for the 0- and 2-lepton channels are shown in \cref{fig:vhbb postfit plots}. The plots show large falling backgrounds, predominantly made up of \Wjets and Z+jets events, and a signal distribution corresponding to the Standard Model Higgs boson peaking around $m_H = 125$ GeV.

\begin{figure}[!htbp]
  \centering
  \begin{subfigure}{.4\textwidth}
    \centering
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/Region_BMax400_BMin250_incFat1_Fat1_Y6051_DSRnoaddbjetsr_T2_L0_distmBB_J0_GlobalFit_conditionnal_mu1.pdf}
  \end{subfigure}%
  \begin{subfigure}{.4\textwidth}
    \centering
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/Region_distmBB_J0_L2_T2_DSR_Y6051_incJet1_Fat1_incFat1_BMin250_BMax400_GlobalFit_conditionnal_mu1.pdf}
  \end{subfigure}
  \caption{
    Post-fit distributions for the 0-lepton (left) and 2-lepton (right) channels in the high purity medium \pTV region, obtained in the combined conditional $\mu=1$ fit to data. The last bin of each plot is an overflow bin.
  }
  \label{fig:vhbb postfit plots}
\end{figure}


\input{chapters/6.vhbb_boosted/tables/mu_systs.tex}



\section{Improved \texorpdfstring{\btagging}{b-tagging} using GNNs}


\section{Conclusion}

Work has been carried out as part of the boosted VHbb analysis group to understand, and implement in the global profile likelihood fit, systematic uncertainties on \Vjets samples. This background modelling work is an essential part of the success of the analysis. So far the fit has proved stable with the inclusion of the \Vjets uncertainties, and detailed studies are now underway to determine the causes behind any observed pulls of the added NPs. Additional work is ongoing to help with the derivation of uncertainties on diboson samples, another important background. The analysis is already advanced, and is now progressing into its final stages. Publication is expected in the new year.

This analysis would benefit greatly from the improved high \pt \btagging enabled by \GNN.
