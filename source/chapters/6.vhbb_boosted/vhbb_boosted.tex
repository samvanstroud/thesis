\chapter{Boosted VHbb Analysis}\label{chap:vhbb_boosted}

The Higgs boson, first observed by \ATLAS and \CMS at the LHC in 2012 \cite{HIGG-2012-27,CMS-HIG-12-028}, is predicted by the standard model to decay primarily to a pair of \bquarks, with a branching factor of $0.582 \pm 0.007$ for $m_H = \SI{125}{\GeV}$ \cite{deFlorian:2016spz}. 
Observation of this decay mode was reported by \ATLAS \cite{HIGG-2018-04} and \CMS \cite{CMS-HIG-18-016} in 2018, establishing the first direct evidence for the Yukawa coupling of the Higgs boson to down-type quarks (see \cref{sec:higgs_yukawa_coupling}).
The \Hbb process is also important for constraining the total decay width of the Higgs \cite{Lafaye:2009vr}.

Whilst the dominant Higgs production mechanism at the LHC is gluon-gluon fusion as outlined in \cref{sec:higgs_pheno}, this mechanism has an overwhelming QCD multijet background and so overall sensitivity to the Higgs is low.
The QCD multijet background refers to events containing one or more strongly produced jets which are not the decay product of heavy resonances, for example $g \to q\bar{q}$.
The gluon-gluon fusion channel contains to leading order only jets in the final state, and therefore it is extremely difficult to distinguish signal events from the overwhelming multijet background.
The \hbb observation therefore searched for Higgs bosons produced in association with a vector boson $V$ (where $V$ can be a \Wboson or \Zboson boson) which subsequently decays leptonically.
The leptonic final states from the decay of the vector boson allow for leptonic triggering whilst at the same time significantly reducing the multijet background.

A closely related analysis \cite{HIGG-2018-52} has more recently measured the associated production of a Higgs boson decaying to \bquarks in events where the vector and Higgs bosons are highly boosted.
The analysis is outlined in \cref{sec:vhbb_overview}.
Modelling studies performed by the author are detailed in \cref{sec:vhbb_modelling}, and the results of the analysis are presented in \cref{sec:vhbb_results}.
The author contributed to various signal and background modelling studies, fit studies, and to the diboson unblinding effort.
This analysis has been published in \rcite{HIGG-2018-52}.
Figures and tables from \rcite{HIGG-2018-52} are reproduced here.
\todo{cite internal note?}

\section{Analysis Overview}\label{sec:vhbb_overview}

The boosted \VHbb analysis is focused on the high transverse momentum regime, which has the benefit of being more sensitive to physics beyond the Standard Model \cite{Mimasu:2015nqa}, but the disadvantage of being more challenging due to the increased difficulty in the accurate reconstructed of highly energy events (discussed in \cref{chap:tracking}).
In order to focus on the \highpt regime, the reconstructed vector boson is required to have $\ptv > \SI{250}{\GeV}$(see \cref{sec:vhbb_object_reco}).
Events are also split into two \ptv bins with the first bin covering $\SI{250}{\GeV} < \ptv < \SI{400}{\GeV}$ and the second covering $\ptv > \SI{400}{\GeV}$, which allows the analysis to account for the improved signal-to-background in the \highpt regime.

The previous \ATLAS analysis in \rcite{HIGG-2018-04} was primarily sensitive to vector bosons with a more modest \ptv boost in the region of 100--\SI{300}{\GeV}.
In this regime, the Higgs candidate was reconstructed using a pair of jets with radius parameter of $R = 0.4$, called \smallR jets.
However in the \highpt regime, the decay products of the Higgs boson become increasingly collimated and the \smallR jets may overlap.
In order to avoid the associated problems and to aid in the reconstruction of the Higgs boson candidate, the present analysis uses instead a \largeR jet with radius parameter $R = 1.0$ to reconstruct the Higgs boson candidate in all channels (see \cref{sec:jet_reco}).
The Higgs candidate is required to have exactly two ghost-assciated and \btagged variable-radius track-jets.
The candidate \largeR jet is reconstructed using jet substructure techniques, for example it is trimmed by removing soft and wide-angle components, which helps to remove particles from the underlying event and pileup collisions \cite{PERF-2012-02}.
Refer to \cref{sec:jet_reco} for more details on jet reconstruction.

On top of the binning in \ptv, selected events are further categorised into 0-, 1- and 2-lepton channels depending on the number of selected charged leptons (electrons and muons) are present in the reconstructed final state (also referred to as 0L, 1L, and 2L respectively).
The 0-lepton channel targets the $\Zboson \higgs \rightarrow \nu\nu \bbbar$ process, the 1-lepton channel targets $\Wboson \higgs \rightarrow \ell\nu \bbbar$, and the 2-lepton channel targets $\Zboson \higgs \rightarrow \ell\ell \bbbar$, where $\ell$ is an electron or muon and $\nu$ is a neutrino.
Each channel has a dedicated set of selections which are listed in more detail in \cref{sec:vhbb_selections}.
Events in the 0- and 1-lepton channels are further split depending on the number of additional \smallR jets
not matched to the Higgs-jet candidate.
The high-purity signal region (HP SR) has zero such jets, while the low-purity signal region (LP SR) has one or more.
%The 0- and 1-lepton channels are split into high- and low-purity signal regions based on the number of additional untagged \smallR jets present in the event.
The 0- and 1-lepton channels also make use of a dedicated \ttbar control region, described in \cref{sec:vhbb_control_region}.
An complete overview of the different analysis regions is given in \cref{tab:SR_CR_definition}.

%
\input{chapters/6.vhbb_boosted/tables/regions.tex}
%


\subsection{Data \& Simulated Samples}\label{sec:vhbb_samples}

The analysis uses \pp\ collision data recorded between 2015 and
2018 by the ATLAS detector~\cite{PERF-2007-01} during Run~2 at the
LHC. This dataset corresponds to an integrated luminosity
of \intlumi.

Data from centre-of-mass energy \come{13} proton-proton collisions at the \LHC recorded over the course of \runtwo were used for the analysis.
The resulting dataset corresponds to a total integrated luminosity of \intlumi (see \cref{fig:run2_lumi}).

An overview of the MC simulated samples used in the analysis is given in \cref{tab:vhbb_samples}.
These samples are used to model the signal and background processes relevant to the analysis, with the exception of teh multijet background which is modelled using a data-driven technique.
Data and simulated events are reconstructed using the same algorithms, and a reweighting is applied to the simulated events in order to match the pile-up distribution
observed in the data.
%
\input{chapters/6.vhbb_boosted/tables/mc_samples.tex}
%

\subsection{Object Reconstruction}\label{sec:vhbb_object_reco}

The presence of neutrinos in the $\Wboson \higgs \rightarrow \ell\nu \bbbar$ and $\Zboson \higgs \rightarrow \ell\ell \bbbar$ signatures can be inferred from a momentum imbalance in the transverse plane \cref{sec:missing_Et}.
The vector boson transverse momentum \ptv is reconstructed as the missing transverse energy \ETmiss in the 0-lepton channel, as the magnitude of the summed \vETmiss and charged-lepton momentum in the 1-lepton channel, and as the transverse momentum of the 2-lepton system in the 2-lepton channel (see \cref{sec:missing_Et}).

Leptons are used for the channel classification and to select relevant events as outlined in \cref{sec:vhbb_selections}.
Electrons and muons are reconstructed as outlined in \cref{sec:lepton_reco}.
Electron identification follows the approach outlined in \rcite{HIGG-2018-04}.
In addition to the likelihood-based method described in \cref{sec:lepton_reco}, \textit{baseline} electrons are required to satisfy $\pt > \SI{7}{\GeV}$, $|\eta| < 2.47$, $\dzerosig < 5$, and $|\zzsth|< \SI{0.5}{\milli\meter}$.
\textit{Signal} electron additionally are required to satisfy a tighter likelihood identification selection.
Muons are required to satisfy $\pt > \SI{7}{\GeV}$, $|\eta| < 2.7$, $\dzerosig < 3$, and $|\zzsth|< \SI{0.5}{\milli\meter}$.
\textit{Baseline} muons are required to pass the `loose' identification described in \rcite{PERF-2015-10}, while \textit{signal} muons are required to pass the `medium' identification working point.
All signal leptons are required to additionally satisfy a $\pt > \SI{27}{\GeV}$ selection criteria, except for muons in the 1-lepton channel where a cut of \SI{25}{\GeV} is used.
The number of baseline leptons is used to categorise the event into the 0-, 1- or 2-lepton channels.
The 1- and 2-lepton channels additionally require one signal lepton to be present.

The track-jets matched to the Higgs candidate are \btagged using the MV2c10 \btagging algorithm \cite{ATL-PHYS-PUB-2015-022,FTAG-2018-01,ATL-PHYS-PUB-2017-013}.
MV2c10 is a machine learning algorithm using a Boosted Decision Tree (BDT) which is tuned to achieve an average \bjet efficiency of \pct{70} on simulated \ttbar events.
At this efficiency working point, rejection factors for \cjets and \ljets are approximately 9 and 304 respectively.
The MV2 algorithm takes inputs from the outputs of a number of low-level algorithms (IPxD, SV1 and JetFitter).
The outputs of the low-level algorithms are provided as inputs to the boosted decision tree.
The efficiency of the tagging algorithm is calibrated to events in data \cite{PERF-2016-05,ATLAS-CONF-2018-006,ATLAS-CONF-2018-001}.
The jet tagging strategy relies on extensive studies into track-jet \btagging in boosted topologies \cite{ATL-PHYS-PUB-2014-013, PERF-2017-04}.

The jet flavour labelling scheme is described in \cref{sec:jet_reco}.


\subsection{Selection Criteria}\label{sec:vhbb_selections}

An extensive list of selection cuts are applied to each event in order to reject background events whilst retaining as many signal events as possible. 
A full list of selection cuts applied to the different analysis regions is given in \cref{tab:vhbb_selection}, while some key selections are listed below.

All channels are require events with at least one \largeR jet with $\pt > \SI{250}{\GeV}$ and $|\eta| < 2.0$.
The vector boson transverse momentum is also required to satisfy $\ptv > \SI{250}{\GeV}$.
The Higgs candidate is chosen as the highest \pt \largeR jet satisfying these requirements.
As mentioned, the candidate \largeR jet is required to have two ghost-assciated and \btagged variable-radius track-jets.
These track-jets are required to have at least two constituent tracks with $\pt > \SI{500}{\MeV}$ and $|\eta| < 2.5$.
The track-jets themselves must satisfy $\pt > \SI{10}{\GeV}$ and $|\eta| < 2.5$.

In the 0-lepton channel, trigger selections are applied using an \ETmiss trigger with a luminosity-dependent threshold between 70--\SI{110}{\GeV}.
In the 1-lepton electron sub-channel a combination of single electron triggers is used with minimum \pt thresholds between 24--\SI{26}{\GeV}.
In the muon sub-channel the same \ETmiss trigger as the 0-lepton channel is used.
Since muons are not used for the \ETmiss trigger calculations, this is in effect a \pt requirement on the muon-neutrino system, which in the analysis phase space is more efficient than a single-muon trigger.
The 2-lepton channel uses the same triggering strategy as the 1-lepton channel.
In all channels, the trigger selections applied are fully efficient for events selected using the full requirements in \cref{tab:vhbb_selection}.

The combined selections in \cref{tab:vhbb_selection} result in a signal efficiency ranging from 6--\pct{16} for the $\Wboson\higgs$ and $\Zboson\higgs$ processes depending on the channel and \ptv bin.

%
\input{chapters/6.vhbb_boosted/tables/event_selection.tex}
%

\subsection{Control Region}\label{sec:vhbb_control_region}

The \ttbar process presents a major background in the 0- and 1-lepton channels.\todo{not sure where the 0L ttbar ETmiss comes from}
In these events, the Higgs candidate is often reconstructed from a correctly tagged \bjet from the top decay $t \to \Wboson b$, and an incorrectly tagged $c$- or \ljet from the subsequent decay of the \Wboson, as shown in \cref{fig:sr_cr_diagrams}.

The only known decay mode of the top quark is via the weak force to a \Wboson and a down-type quark. (it is the only quark heavy enough to decay into an on-shell \Wboson).
Overwhelmingly (\pct{96} of the time) the down-type quark is a \bquark
Hence, the second top quark is also likely to result in a second tagged \btagged track-jet outside of the \largeR Higgs candidate.
To ensure sufficient \ttbar rejections, 0- and 1-lepton channel signal regions are defined using a veto on events with \btagged track-jets outside the Higgs-jet candidate.
These events are used to construct a control region (CR) which is enriched in \ttbar events.
The CR is used to constrain the normalisation of the \ttbar background in the fit.

%
\begin{figure}[!htbp]
  \centering
  \includegraphics[width=0.65\textwidth]{chapters/6.vhbb_boosted/figs/sr_cr_diagrams.pdf}
  \caption{
    Diagrams or the signal process (top) and the 0-lepton and 1-lepton \ttbar backgrounds (middle, bottom).
    Object to the right of centre are reconstructed within the \largeR jet.
    For the backgrounds, the \largeR jet contains a mis-tagged $c$- or \ljet.
  }
  \label{fig:sr_cr_diagrams}
\end{figure}
%

\subsection{Background Composition}\label{sec:vebb_background_composition}

After the selections described in \cref{sec:vhbb_selections} the number of background events mimicking the \VHbb signal is greatly reduced.
However, the number of background events still greatly outnumbers that of signal events.
The background processes are channel dependent.
In the 0-lepton channel the dominant sources of backgrounds are \Zjets ($\Zboson \to \nu\nu$) and \ttbar, with \Wjets and diboson events being subdominant.
In the event of $\Wboson \to \tau\nu$, and subsequent decay of the $\tau$, or the lack of the successful reconstruction of the $e$ or $\mu$, \Wjets can also contribute to the 0-lepton channel.
\ttbar and \Wjets (with a leptonic decay of the \Wboson as in $\Wboson \to \ell\nu$) are dominant in the 1-lepton channel, while single-top is subdominant.
In the 2-lepton channel, \Zjets ($\Zboson \to \ell\ell$) is again dominant followed by \Zboson\Zboson diboson events.

The diboson background $VV$ consists primarily of \Wboson\Zboson and \Zboson\Zboson events in which the \Zboson decays to a pair of \bquarks.
This process very closely matches the signal, with a resonant peak occurring at $m_Z = \SI{91}{\GeV}$ and so is considered as an 
irreducible background.

The $t\overline{t} V$, $t\overline{t} H$ and multijet backgrounds are negligible in the analysis phase space after the selections have been applied, with the exception of the 1-lepton electron sub-channel, in which multijet background is not ignored.
The multijet background is made up of jets with semileptonic heavy-flavour-hadron decays (e.g. $b \to c \ell \nu$) and jets which are mis-tagged by the flavour tagging algorithm MV2c10.


\section{Modelling \& Systematic Uncertainties}\label{sec:vhbb_modelling}
% modelling note \cite{Bell:2316951}

% Modelling (i.e. simulation of SM processes) is used for predicting the outcomes of the analysis and for assessing impact of sources of different systematics uncertainties. 

% Modelling is used to predict the outcomes of the analysis and to assess the impact of sources of different systematic uncertainty.
% Signal and background modelling has has primarily consisted of using Monte Carlo (MC) generators to produce simulated events.
% The uncertainties on the simulated output must be well understood to perform a successful analysis.

In order to observe a certain process, for example \VHbb, an increase in the number of observed events with respect to the background-only hypothesis is looked for.
The excess is often relatively small against the total number of background events, and hence accurate modelling of the expected number of background and signal events is crucial for successfully performing the analysis.

Systemic uncertainties are extensively employed to give the fit model described in \cref{sec:vhbb_fit} enough flexibility to account of inaccuracies in the model prediction

The main types of systematic uncertainty are theoretical, experimental, and modelling.
Theoretical uncertainties arise due to imperfect precision used in e.g. QCD calculations
Experimental uncertainties arise due to the limited due to limited detector precision, imperfect reconstruction algorithms (in particular the \btagging algorithms), and due to the imperfect measurement of pile-up and integrated luminosity.
Modelling uncertainties arise due to the imperfections in the generators used to produce the the simulated signal and background events.

Theoretical and experimental uncertainties are described in less detail in this section, but are still fully taken into account in the fit model described in \cref{sec:vhbb_fit}.
Modelling uncertainties are described in detail in the following sections.
Modelling uncertainties:
\textit{Nominal} samples are are used as a reference to which different variations can be compared.
The nominal samples are chosen as the best possible representation of the underlying physical process.
\textit{Alternative} samples are used to understand inaccuracies that may be present in the nominal samples.
Some aspect of the nominal model is varied, and the discrepancy with respect to the nominal model is quantified.
The discrepancy is used to systematic uncertainty associated with the model parameter which was changed.


\subsection{Vector Boson + Jets Modelling}

After event selection, the \Vjets background is a dominant background in all three analysis channels as described in \cref{sec:vebb_background_composition}.

In order to access uncertainties associated with the use of MC generators, variations of the data are produced using alternative generators or variation of nominal generator parameters.
The variation of nominal generator parameters can in certain cases be implemented using internal weight variations stored alongside the nominal events, and in other cases a new independent sample must be generated. The nominal generator used for \Vjets events is \textsc{Sherpa 2.2.1}, while \textsc{MadGraph5\_aMC@NLO+Pythia8} (which uses different parton showering models) is used as an alternative generator.

Several sources of uncertainty, summarised in \cref{sec:sources_of_uncertainties}, have been assessed.

\subsection{Sources of Systematic Uncertainties}\label{sec:sources_of_uncertainties}

This section briefly describes the different sources of uncertainty in the predictive model used in the analysis, and how each source of uncertainty is implemented within the analysis procedure.
Sources of systematic uncertainty that are understood using variations in samples are listed in \cref{tab:sources_of_uncertainty}:
%
\input{chapters/6.vhbb_boosted/tables/sources_of_uncertainty.tex}
%

\subsubsection{Alternative Samples}
As mentioned, alternative samples of \Vjets events was generated using \textsc{MadGraph5\_aMC@NLO+Pythia8}, and the results are compared with the nominal \textsc{Sherpa 2.2.1} samples. This allows for a comparison of different parton showering and underlying event models, and derivation of the systematic uncertainties on the nominal choice of models.

\subsubsection{Internal Weight Variations}
As production of large MC samples is computationally expensive, a technique in state of the art simulation packages is to store some sources of variation as internal weights, which can be generated alongside the nominal samples, saving computation time. When filling histograms for the variations, bins are incremented by the internal weight of the event associated with the variation in question.

Nominal signal samples generated with \textsc{Sherpa 2.2.1} include systematic variations of certain modelling parameters which are stored as alternative event weights. The samples contain event weight variations which correspond to variations of renormalisation scale $\mu_R$, and factorisation scale $\mu_F$, of $0.5$ and $2$ times the nominal value. Additionally stored is event weight variations corresponding to $30$ different variations on the PDF and two variations of the strong coupling constant $\alpha_S$. Variations of $\alpha_S$ were found to have negligible impact on the results of the analysis, and are not discussed further. 

\subsubsection{Parameterisation Methods}
While the inclusion of internal weight variation in MC event generators has decreased simulation times and increased available statistics, there are in \textsc{Sherpa 2.2.1} currently some sources of systematic uncertainty that are unable to be stored as internal weight variations due to technical limitations. Two such systematics relate to the choice of CKKW matrix element merging scale, and resummation scale (QSF). The generation of high statistics alternative samples is a time consuming process, as is typically not done for all samples for every new generator release. A method to parameterise the systematic variation using one sample, and to then apply this parameterisation to another sample, has been developed by the ATLAS SUSY group \cite{Anders:2125718}. This method was used to derive CKKW and QSF uncertainties for the nominal \textsc{Sherpa 2.2.1} sample, using a previous (lower statistic) \textsc{Sherpa 2.1} alternative sample. The resulting uncertainties were studied and found to be negligible in comparison with systemics from other sources.


\subsection{Shape Uncertainties}
\begin{comment}
For each variation two different sets of systematics are determined: acceptance uncertainties for the analysis categories and shape uncertainties for the $p_T^V$ and $m_{bb}$ shape. These two distributions were chosen since Run 1 experience shows that they are sufficiently decorrelated, the most important input variables for the BDTs and uncertainties on those two variables cover sufficiently shape uncertainties in the other input variables.
\end{comment}
In order to derive shape uncertainties (which as the name suggests affect shapes but not overall normalisations of distributions), the following procedure is carried out. Normalised distributions of the reconstructed Higgs candidate mass $m_J$ are compared for the nominal sample and variations. For each variation, the ratio of the variation to nominal is calculated, and an analytic function is fit to those sources of variation which have a ratio deviating from unity. If different analysis regions or channels show the same pattern of variation, a common uncertainty is assigned. An example of a significant source of uncertainty, arising from choice of factorisation scale $\mu_R$ is shown in \cref{fig:vhbb muR shape fitted}. An exponential function has been fitted to the ratio of the normalised distributions. Two different analysis regions (medium and high \pTV bins) are shown. The difference of the shape of the variation means that two separate uncertainties have to be added in the fit, and applied individually in each \pTV region. 
%
\begin{figure}[!htbp]
    \centering
    \begin{subfigure}{.4\textwidth}
      \centering
      \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/1L_Whf_2tag1pfat0pjet_250_400ptv_SRCR_mJ_SysMUR_T_Norm.pdf}
      \caption{}
      \label{fig:vhbb muR shape fitted sub1}
    \end{subfigure}%
    \begin{subfigure}{.4\textwidth}
      \centering
      \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/1L_Whf_2tag1pfat0pjet_400ptv_SRCR_mJ_SysMUR_T_Norm.pdf}
      \caption{}
      \label{fig:vhbb muR shape fitted sub2}
    \end{subfigure}
    \vspace{-0.5em}
    \caption{Normalised distributions of leading fat jet mass $m_J$ for medium (\ref{fig:vhbb muR shape fitted sub1}) and high (\ref{fig:vhbb muR shape fitted sub2}) \pTV analysis regions for W+heavy-flavour-jets in the 0 lepton channel.
    Merged in heavy flavours, high and low purity signal regions.
    The renormalisation scale $\mu_R$ has been varied by a factor of 2 (``1up'') and 0.5 (``1down''). An exponential function has been fit to the ratio.}
    \label{fig:vhbb muR shape fitted}
\end{figure}

\subsection{Acceptance Uncertainties}
Several different types of acceptance uncertainties have been calculated. These are implemented as nuisance parameters in the fit and for the most part account for the migration of events between different analysis regions. The list acceptance uncertainties relevant to the \Vjets processes are given summarised below.
%
\begin{itemize}
    \item \textbf{Overall normalisation:} only relevant where normalisation cannot be left floating (i.e. determined in the fit).
    %
    \item \textbf{SR-to-CR relative acceptance:} the uncertainty on the normalisation of the signal region due to events migrating between the signal and control regions.
    %
    \item \textbf{HP-to-LP relative acceptance:} the uncertainty on the normalisation of the high-purity (HP) signal region due to events migrating between the high- and low-purity signal regions.
    %
    \item \textbf{Medium-to-high} \pTV \textbf{relative acceptance:} describes any 'shape' effect in \pTV distribution, given that the analysis only uses two \pTV bins (medium and high).
    %
    \item \textbf{Flavour relative acceptance:} for each flavour V$xx$, where $xx\in$ \{bc,bl,cc\} the ratio of V$xx$/Vbb events is calculated. This corresponds to the uncertainty of Vbb events due to the miss-tagging of other flavours V$xx$. 
\end{itemize}
%
The uncertainties on different systematics are summed in quadrature to give a total uncertainty on each region. A summary of the different acceptance uncertainties that were derived in this way and subsequently applied in the fit are given in \cref{tab:Vjets acceptance uncerts}. An effort has been made, wherever possible, to harmonise similar uncertainties across different analysis regions and channels.


\subsubsection{Flavour Composition Uncertainties}
\begin{comment}
The ð‘Š/ð‘+jets simulated event samples are split into 6 categories depending on the â€˜truthâ€™ labels of
the track-jets ghost-associated to the Higgs-jet candidate: ð‘Š/ð‘ + ð‘ð‘, ð‘Š/ð‘ + ð‘ð‘, ð‘Š/ð‘ + ð‘ð‘™, ð‘Š/ð‘ + ð‘ð‘,
ð‘Š/ð‘ + ð‘ð‘™ and ð‘Š/ð‘ + ð‘™ð‘™; in this notation ð‘™ refers to a light-flavour jet.4 The ð‘Š/ð‘ + ð‘ð‘ fraction corresponds
to approximately 80% of the total ð‘Š/ð‘+jets background. This categorisation is used in the uncertainties
variations of the ratios ð‘‰ + ð‘ð‘/ð‘‰ + ð‘ð‘, ð‘‰ + ð‘ð‘™/ð‘‰ + ð‘ð‘ and ð‘‰ + ð‘ð‘/ð‘‰ + ð‘ð‘ to cover uncertainties on the
flavour composition in ð‘‰+jets production, see Section 7.
\end{comment}



\subsubsection{Summary}
%
\input{chapters/6.vhbb_boosted/tables/V+jets-acceptance-uncertainties-summary}
%







\subsection{Diboson Modelling}


...




\section{Fit Model}\label{sec:vhbb_fit}



\begin{comment}
  All initial background distribution shapes prior to the fit (described in Section 8), except those for multÄ³et, are estimated from the samples of simulated events. The multÄ³et shape and normalisation are determined using data
  \end{comment}

\begin{comment}
  The normalisation on the diboson background is left floating in the fit, i.e. measured simulatneously along with the $VH$ signal


  In the statistical analysis described in Section 8, the components ð‘Š/ð‘ + ð‘ð‘, ð‘Š/ð‘ + ð‘ð‘, ð‘Š/ð‘ + ð‘ð‘™ and
ð‘Š/ð‘ + ð‘ð‘ are treated as a single background component denoted by ð‘Š/ð‘+HF. The ð‘Š+HF and ð‘+HF
contributions, which together constitute 90% of ð‘‰+jets background, are estimated separately, each with its
own normalisation factor determined from the fit to data
\end{comment}

%The \HiggsJet\ mass candidate in the different signal
%regions are used as the discriminant variable and are combined using a
%binned maximum-likelihood fit, referred to as the global likelihood
%fit, which allows the signal yield and the background normalisations
%to be extracted.

%The signal is extracted from a combined profile likelihood fit to the \largeR jet mass, using several signal and control regions. The yield of diboson production $VZ$ with $Z \rightarrow b\bar{b}$ is also measured using the same fit and provides a validation of the analysis. The cross-section measurements are performed within the simplified template cross-section (STXS) framework~\cite{deFlorian:2016spz, Badger:2016bpw}. These measurements are then used to constrain anomalous couplings in a Standard Model effective field theory (SMEFT)~\cite{Contino:2013kra}.

A global profile likelihood fit is used to extract the signal strength $\mu$ and its significance from the data. This statistical setup treats each bin as a Poisson counting experiment. The combined likelihood over $N$ bins, without considering sources of systematic uncertainty, is given by
%
\begin{equation}
    \mathcal{L}(\mu) = \prod_{i=1}^N \frac{(\mu s_i + b_i)^{n_i}}{n_i!} \exp \left[ - (\mu s_i + b_i) \right],
\end{equation}
%
where $s_i$ ($b_i$) is the expected number of signal (background) events in bin $i$, and $n_i$ is the number of events observed in data in bin $i$. The presence of systematic uncertainties which can affect the expected numbers of signal and background events necessitates the addition of nuisance parameters (NPs), $\theta$, to the likelihood. Each source of systematic uncertainty for \Vjets samples discussed in the previous section was implemented as a NP $\theta_j$ in the fit. The presence of NPs modifies the likelihood as 
%
\begin{equation}
    \mathcal{L}(\mu) \rightarrow \mathcal{L}(\mu, \theta) = \mathcal{L}(\mu) \times \mathcal{L}(\theta) , \quad s_i \rightarrow s_i(\theta) , \quad b_i \rightarrow b_i(\theta),
\end{equation}
%
where
%
\begin{equation}
    \mathcal{L}(\theta) = \prod_{\theta_j \in \theta} \frac{\exp\left[{-\theta_j^2/2}\right]}{\sqrt{2\pi}}.
\end{equation}
%


Statstical uncertainty is also present.

\section{Results}\label{sec:vhbb_results}

\begin{comment}
  paper abstract
  The measured
  signal strength, defined as the ratio of the measured signal yield to
  that predicted by the Standard Model, is $0.72 ^{+0.39}_{-0.36}$
  corresponding to an observed (expected) significance of 2.1 (2.7)
  standard deviations. Cross-sections of associated production of a
  Higgs boson decaying into $b$ quark pairs with a \Wboson or \Zboson gauge
  boson, decaying into leptons, are measured in two exclusive
  vector boson transverse momentum regions, 250--\SI{400}{\GeV} and above \SI{400}{\GeV}, and
  interpreted as constraints on anomalous couplings in the framework of
  a Standard Model effective field theory.

  %For a Higgs boson mass of \SI{125}{\GeV}, an excess of events over the expected background from other Standard Model processes is found
  %with an observed significance of $3.5$ standard deviations, compared to an expectation of $3.0$
  %standard deviations. This excess provides evidence for the Higgs boson decay into b-quarks
  %and for its production in association with a vector boson. Assuming the Standard Model production 0.19
  %cross-section, the results are consistent with the value of the Yukawa coupling to b-quarks in the Standard Model.
\end{comment}

\subsection{Pre-fit Yields}


\subsection{Post-fit Results}

Post-fit $m_J$ distributions in the high-purity medium \pTV regions for the 0- and 2-lepton channels are shown in \cref{fig:vhbb postfit plots}. The plots show large falling backgrounds, predominantly made up of \Wjets and Z+jets events, and a signal distribution corresponding to the Standard Model Higgs boson peaking around $m_H = 125$ GeV.

\begin{figure}[!htbp]
  \centering
  \begin{subfigure}{.4\textwidth}
    \centering
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/Region_BMax400_BMin250_incFat1_Fat1_Y6051_DSRnoaddbjetsr_T2_L0_distmBB_J0_GlobalFit_conditionnal_mu1.pdf}
  \end{subfigure}%
  \begin{subfigure}{.4\textwidth}
    \centering
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/Region_distmBB_J0_L2_T2_DSR_Y6051_incJet1_Fat1_incFat1_BMin250_BMax400_GlobalFit_conditionnal_mu1.pdf}
  \end{subfigure}
  \caption{
    Post-fit distributions for the 0-lepton (left) and 2-lepton (right) channels in the high purity medium \pTV region, obtained in the combined conditional $\mu=1$ fit to data. The last bin of each plot is an overflow bin.
  }
  \label{fig:vhbb postfit plots}
\end{figure}


\input{chapters/6.vhbb_boosted/tables/mu_systs.tex}


\subsection{STXS Interpretation}

%%STXS measurements are designed to proceed in stages of increasing
%granularity with more recorded data.
%In â€˜stage 0â€™, cross-sections are
%measured separately for the four main production modes in a fiducial
%Higgs boson rapidity region $|y_H|< 2.5$ and in â€˜stage 1â€™, these
%regions are split into 31 subregions according to the transverse
%momentum of the weak gauge boson $V$ for $VH$, $V\rightarrow$ leptons
%production. Stage-1 STXS were measured recently for $VH, H\rightarrow
%b\bar{b}$ with 80 \ifb of 13 TeV ATLAS data in the following bins:
%$\ptv<75~\GeV$, $75<\ptv<150~\GeV$ and $\ptv>250~\GeV$, with results in
%agreement with SM predictions~\cite{HIGG-2018-50}. In this letter
%â€˜stage 1â€™ results are presented in two kinematic fiducial volumes:
%$250<\ptv>450~\GeV$ and $\ptv>450~\GeV$.

\section{Improved \texorpdfstring{\btagging}{b-tagging} using GNNs}


\section{Conclusion}

Work has been carried out as part of the boosted VHbb analysis group to understand, and implement in the global profile likelihood fit, systematic uncertainties on \Vjets samples. This background modelling work is an essential part of the success of the analysis. So far the fit has proved stable with the inclusion of the \Vjets uncertainties, and detailed studies are now underway to determine the causes behind any observed pulls of the added NPs. Additional work is ongoing to help with the derivation of uncertainties on diboson samples, another important background. The analysis is already advanced, and is now progressing into its final stages. Publication is expected in the new year.

This analysis would benefit greatly from the improved high \pt \btagging enabled by \GNN.
