\chapter{Boosted VHbb Analysis}\label{chap:vhbb_boosted}

The Higgs boson, first observed by \ATLAS and \CMS at the LHC in 2012 \cite{HIGG-2012-27,CMS-HIG-12-028}, is predicted by the standard model to decay primarily to a pair of \bquarks, with a branching factor of $0.582 \pm 0.007$ for $m_H = \SI{125}{\GeV}$ \cite{deFlorian:2016spz}. 
Observation of this decay mode was reported by \ATLAS \cite{HIGG-2018-04} and \CMS \cite{CMS-HIG-18-016} in 2018, establishing the first direct evidence for the Yukawa coupling of the Higgs boson to down-type quarks (see \cref{sec:higgs_yukawa_coupling}).
The \Hbb process is also important for constraining the total decay width of the Higgs \cite{Lafaye:2009vr}.

Whilst the dominant Higgs production mechanism at the LHC is gluon-gluon fusion as outlined in \cref{sec:higgs_pheno}, this mechanism has an overwhelming QCD multijet background and so overall sensitivity to the Higgs is low.
The QCD multijet background refers to events containing one or more strongly produced jets which are not the decay product of heavy resonances, for example $g \to q\bar{q}$.
The gluon-gluon fusion channel contains to leading order only jets in the final state, and therefore it is extremely difficult to distinguish signal events from the overwhelming multijet background.
The \hbb observation therefore searched for Higgs bosons produced in association with a vector boson $V$ (where $V$ can be a \Wboson or \Zboson boson) which subsequently decays leptonically.
The leptonic final states from the decay of the vector boson allow for leptonic triggering whilst at the same time significantly reducing the multijet background.

A closely related analysis \cite{HIGG-2018-52} has more recently measured the associated production of a Higgs boson decaying to \bquarks in events where the vector and Higgs bosons are highly boosted.
The analysis is outlined in \cref{sec:vhbb_overview}.
Modelling studies performed by the author are detailed in \cref{sec:vhbb_modelling}, and the results of the analysis are presented in \cref{sec:vhbb_results}.
The author contributed to various signal and background modelling studies, fit studies, and to the diboson unblinding effort.
This analysis has been published in \rcite{HIGG-2018-52}.
Figures and tables from \rcite{HIGG-2018-52} are reproduced here.

\section{Analysis Overview}\label{sec:vhbb_overview}

The boosted \VHbb analysis is focused on the high transverse momentum regime, which has the benefit of being more sensitive to physics beyond the Standard Model \cite{Mimasu:2015nqa}, but the disadvantage of being more challenging due to the increased difficulty in the accurate reconstructed of highly energy events (discussed in \cref{chap:tracking}).
In order to focus on the \highpt regime, the reconstructed vector boson is required to have $\ptv > \SI{250}{\GeV}$(see \cref{sec:vhbb_object_reco}).
Events are also split into two \ptv bins with the first bin covering $\SI{250}{\GeV} < \ptv < \SI{400}{\GeV}$ and the second covering $\ptv > \SI{400}{\GeV}$, which allows the analysis to account for the improved signal-to-background in the \highpt regime.

The previous \ATLAS analysis in \rcite{HIGG-2018-04} was primarily sensitive to vector bosons with a more modest \ptv boost in the region of 100--\SI{300}{\GeV}.
In this regime, the Higgs candidate was reconstructed using a pair of jets with radius parameter of $R = 0.4$, called \smallR jets.
However in the \highpt regime, the decay products of the Higgs boson become increasingly collimated and the \smallR jets may overlap.
In order to avoid the associated problems and to aid in the reconstruction of the Higgs boson candidate, the present analysis uses instead a \largeR jet with radius parameter $R = 1.0$ to reconstruct the Higgs boson candidate in all channels (see \cref{sec:jet_reco}).
The Higgs candidate is required to have exactly two ghost-assciated and \btagged variable-radius track-jets.
The candidate \largeR jet is reconstructed using jet substructure techniques, for example it is trimmed by removing soft and wide-angle components, which helps to remove particles from the underlying event and pileup collisions \cite{PERF-2012-02}.
Refer to \cref{sec:jet_reco} for more details on jet reconstruction.

On top of the binning in \ptv, selected events are further categorised into 0-, 1- and 2-lepton channels depending on the number of selected charged leptons (electrons and muons) are present in the reconstructed final state (also referred to as 0L, 1L, and 2L respectively).
The 0-lepton channel targets the $\Zboson \higgs \rightarrow \nu\nu \bbbar$ process, the 1-lepton channel targets $\Wboson \higgs \rightarrow \ell\nu \bbbar$, and the 2-lepton channel targets $\Zboson \higgs \rightarrow \ell\ell \bbbar$, where $\ell$ is an electron or muon and $\nu$ is a neutrino.
Each channel has a dedicated set of selections which are listed in more detail in \cref{sec:vhbb_selections}.
Events in the 0- and 1-lepton channels are further split depending on the number of additional \smallR jets
not matched to the Higgs-jet candidate.
The high-purity signal region (HP SR) has zero such jets, while the low-purity signal region (LP SR) has one or more.
%The 0- and 1-lepton channels are split into high- and low-purity signal regions based on the number of additional untagged \smallR jets present in the event.
The 0- and 1-lepton channels also make use of a dedicated \ttbar control region, described in \cref{sec:vhbb_control_region}.
An complete overview of the different analysis regions is given in \cref{tab:SR_CR_definition}.

%
\input{chapters/6.vhbb_boosted/tables/regions.tex}
%


\subsection{Data \& Simulated Samples}\label{sec:vhbb_samples}

The analysis uses \pp\ collision data recorded between 2015 and
2018 by the ATLAS detector~\cite{PERF-2007-01} during Run~2 at the
LHC. This dataset corresponds to an integrated luminosity
of \intlumi.

Data from centre-of-mass energy \come{13} proton-proton collisions at the \LHC recorded over the course of \runtwo were used for the analysis.
The resulting dataset corresponds to a total integrated luminosity of \intlumi (see \cref{fig:run2_lumi}).

An overview of the MC simulated samples used in the analysis is given in \cref{tab:vhbb_samples}.
These samples are used to model the signal and background processes relevant to the analysis, with the exception of the multijet background which is modelled using a data-driven technique.
Data and simulated events are reconstructed using the same algorithms, and a reweighting is applied to the simulated events in order to match the pile-up distribution
observed in the data.
%
\input{chapters/6.vhbb_boosted/tables/mc_samples.tex}
%

\subsection{Object Reconstruction}\label{sec:vhbb_object_reco}

The presence of neutrinos in the $\Wboson \higgs \rightarrow \ell\nu \bbbar$ and $\Zboson \higgs \rightarrow \ell\ell \bbbar$ signatures can be inferred from a momentum imbalance in the transverse plane \cref{sec:missing_Et}.
The vector boson transverse momentum \ptv is reconstructed as the missing transverse energy \ETmiss in the 0-lepton channel, as the magnitude of the summed \vETmiss and charged-lepton momentum in the 1-lepton channel, and as the transverse momentum of the 2-lepton system in the 2-lepton channel (see \cref{sec:missing_Et}).

Leptons are used for the channel classification and to select relevant events as outlined in \cref{sec:vhbb_selections}.
Electrons and muons are reconstructed as outlined in \cref{sec:lepton_reco}.
Electron identification follows the approach outlined in \rcite{HIGG-2018-04}.
In addition to the likelihood-based method described in \cref{sec:lepton_reco}, \textit{baseline} electrons are required to satisfy $\pt > \SI{7}{\GeV}$, $|\eta| < 2.47$, $\dzerosig < 5$, and $|\zzsth|< \SI{0.5}{\milli\meter}$.
\textit{Signal} electron additionally are required to satisfy a tighter likelihood identification selection.
Muons are required to satisfy $\pt > \SI{7}{\GeV}$, $|\eta| < 2.7$, $\dzerosig < 3$, and $|\zzsth|< \SI{0.5}{\milli\meter}$.
\textit{Baseline} muons are required to pass the `loose' identification described in \rcite{PERF-2015-10}, while \textit{signal} muons are required to pass the `medium' identification working point.
All signal leptons are required to additionally satisfy a $\pt > \SI{27}{\GeV}$ selection criteria, except for muons in the 1-lepton channel where a cut of \SI{25}{\GeV} is used.
The number of baseline leptons is used to categorise the event into the 0-, 1- or 2-lepton channels.
The 1- and 2-lepton channels additionally require one signal lepton to be present.

The track-jets matched to the Higgs candidate are \btagged using the MV2c10 \btagging algorithm \cite{ATL-PHYS-PUB-2015-022,FTAG-2018-01,ATL-PHYS-PUB-2017-013}.
MV2c10 is a machine learning algorithm using a Boosted Decision Tree (BDT) which is tuned to achieve an average \bjet efficiency of \pct{70} on simulated \ttbar events.
At this efficiency working point, rejection factors for \cjets and \ljets are approximately 9 and 304 respectively.
The MV2 algorithm takes inputs from the outputs of a number of low-level algorithms (IPxD, SV1 and JetFitter).
The outputs of the low-level algorithms are provided as inputs to the boosted decision tree.
The efficiency of the tagging algorithm is calibrated to events in data \cite{PERF-2016-05,ATLAS-CONF-2018-006,ATLAS-CONF-2018-001}.
The jet tagging strategy relies on extensive studies into track-jet \btagging in boosted topologies \cite{ATL-PHYS-PUB-2014-013, PERF-2017-04}.

The jet flavour labelling scheme is described in \cref{sec:jet_reco}.


\subsection{Selection Criteria}\label{sec:vhbb_selections}

An extensive list of selection cuts are applied to each event in order to reject background events whilst retaining as many signal events as possible. 
A full list of selection cuts applied to the different analysis regions is given in \cref{tab:vhbb_selection}, while some key selections are listed below.

All channels are require events with at least one \largeR jet with $\pt > \SI{250}{\GeV}$ and $|\eta| < 2.0$.
The vector boson transverse momentum is also required to satisfy $\ptv > \SI{250}{\GeV}$.
The Higgs candidate is chosen as the highest \pt \largeR jet satisfying these requirements.
As mentioned, the candidate \largeR jet is required to have two ghost-assciated and \btagged variable-radius track-jets.
These track-jets are required to have at least two constituent tracks with $\pt > \SI{500}{\MeV}$ and $|\eta| < 2.5$.
The track-jets themselves must satisfy $\pt > \SI{10}{\GeV}$ and $|\eta| < 2.5$.

In the 0-lepton channel, trigger selections are applied using an \ETmiss trigger with a luminosity-dependent threshold between 70--\SI{110}{\GeV}.
In the 1-lepton electron sub-channel a combination of single electron triggers is used with minimum \pt thresholds between 24--\SI{26}{\GeV}.
In the muon sub-channel the same \ETmiss trigger as the 0-lepton channel is used.
Since muons are not used for the \ETmiss trigger calculations, this is in effect a \pt requirement on the muon-neutrino system, which in the analysis phase space is more efficient than a single-muon trigger.
The 2-lepton channel uses the same triggering strategy as the 1-lepton channel.
In all channels, the trigger selections applied are fully efficient for events selected using the full requirements in \cref{tab:vhbb_selection}.

The combined selections in \cref{tab:vhbb_selection} result in a signal efficiency ranging from 6--\pct{16} for the $\Wboson\higgs$ and $\Zboson\higgs$ processes depending on the channel and \ptv bin.

%
\input{chapters/6.vhbb_boosted/tables/event_selection.tex}
%

\subsection{Control Regions}\label{sec:vhbb_control_region}

The \ttbar process presents a major background in the 0- and 1-lepton channels.\todo{not sure where the 0L ttbar ETmiss comes from}
In these events, the Higgs candidate is often reconstructed from a correctly tagged \bjet from the top decay $t \to \Wboson b$, and an incorrectly tagged $c$- or \ljet from the subsequent decay of the \Wboson, as shown in \cref{fig:sr_cr_diagrams}.

The only known decay mode of the top quark is via the weak force to a \Wboson and a down-type quark. (it is the only quark heavy enough to decay into an on-shell \Wboson).
Overwhelmingly (\pct{96} of the time) the down-type quark is a \bquark
Hence, the second top quark is also likely to result in a second tagged \btagged track-jet outside of the \largeR Higgs candidate.
To ensure sufficient \ttbar rejections, 0- and 1-lepton channel signal regions are defined using a veto on events with \btagged track-jets outside the Higgs-jet candidate.
These events are used to construct a control region (CR) which is enriched in \ttbar events.
The CR is used to constrain the normalisation of the \ttbar background in the fit.

%
\begin{figure}[!htbp]
  \centering
  \includegraphics[width=0.65\textwidth]{chapters/6.vhbb_boosted/figs/sr_cr_diagrams.pdf}
  \caption{
    Diagrams or the signal process (top) and the 0-lepton and 1-lepton \ttbar backgrounds (middle, bottom).
    Object to the right of centre are reconstructed within the \largeR jet.
    For the backgrounds, the \largeR jet contains a mis-tagged $c$- or \ljet.
  }
  \label{fig:sr_cr_diagrams}
\end{figure}
%

\subsection{Background Composition}\label{sec:vebb_background_composition}

After the selections described in \cref{sec:vhbb_selections} the number of background events mimicking the \VHbb signal is greatly reduced.
However, the number of background events still greatly outnumbers that of signal events.
The background processes are channel dependent.
In the 0-lepton channel the dominant sources of backgrounds are \Zjets ($\Zboson \to \nu\nu$) and \ttbar, with \Wjets and diboson events being subdominant.
In the event of $\Wboson \to \tau\nu$, and subsequent hadronic decay of the $\tau$ or lack of successful reconstruction/selection of the leptonic decay products, \Wjets can also contribute to the 0-lepton channel.
\ttbar and \Wjets (with a leptonic decay of the \Wboson as in $\Wboson \to \ell\nu$) are dominant in the 1-lepton channel, while single-top is subdominant.
In the 2-lepton channel, \Zjets ($\Zboson \to \ell\ell$) is again dominant followed by \Zboson\Zboson diboson events.

The diboson background $VV$ consists primarily of \Wboson\Zboson and \Zboson\Zboson events in which the \Zboson decays to a pair of \bquarks.
This process very closely matches the signal, with a resonant peak occurring at $m_Z = \SI{91}{\GeV}$ and so is considered as an 
irreducible background ($V$+\bjets is also irreducible).

The $t\overline{t} V$, $t\overline{t} H$ and multijet backgrounds are negligible in the analysis phase space after the selections have been applied, with the exception of the 1-lepton electron sub-channel, in which multijet background is not ignored.
The multijet background is made up of jets with semileptonic heavy-flavour-hadron decays (e.g. $b \to c \ell \nu$) and jets which are mis-tagged by the flavour tagging algorithm MV2c10.

The contributions from the different backgrounds are modelled using Monte Carlo event generators and the impacts on the analysis are studied in \cref{sec:vhbb_modelling}.
The multijet background is not modelled but instead estimated using a data-driven technique.


\section{Systematic Uncertainties \& Background Modelling}\label{sec:vhbb_modelling}
% modelling note \cite{Bell:2316951}

Systemic uncertainties are extensively employed to give the fit model described in \cref{sec:vhbb_fit} enough flexibility to account for inaccuracies in the various inputs to the fit.
Two main types of systematic uncertainty are considered: experimental and modelling.
%Theoretical uncertainties arise due to imperfect precision used in e.g. QCD calculations.
Experimental uncertainties arise due to the limited due to limited detector precision, imperfect reconstruction algorithms (in particular the \btagging algorithms), and due to the imperfect measurement of pile-up and integrated luminosity.
Modelling is the simulation processes relevant to the analysis using Monte-Carlo (MC) event generators, and is used to predict the outcome of the analysis.
Modelling uncertainties arise due to the imperfections in the simulation of signal and background events, for example differences between event generators, or use of different model parameters when producing simulated events.
In order to observe a certain process, for example \VHbb, an increase in the number of observed events with respect to the background-only hypothesis is looked for.
The excess is often relatively small against the total number of background events, and hence accurate modelling of the expected number of background and signal events is crucial for successfully performing the analysis.
Particular care is paid to the uncertainties on the modelling predictions as discussed in this section.

Modelling uncertainties are described in detail in the following sections.
Modelling uncertainties:
\textit{Nominal} samples are are used as a reference to which different variations can be compared.
The nominal samples are chosen as the best possible representation of the underlying physical process.
\textit{Alternative} samples are used to understand inaccuracies that may be present in the nominal samples.
Some aspect of the nominal model is varied, and the discrepancy with respect to the nominal model is quantified.
The discrepancy is used to systematic uncertainty associated with the model parameter which was changed.

Modelling studies involving $c$- and \ljets is hampered by the low available statistics of jets pass the analysis selections, due to the high rejection rates of the \btagging algorithm MV2c10.
For modelling studies therefore, truth tagging (TT) is employed to ensure sufficient numbers of jets are available to calculate uncertainties.
TT works by computing a 2-dimensional efficiency map using the jet \pt and jet $\eta$.
The two leading track-jets associated to the \largeR jet automatically passes the \btagging requirement, and are weighted based on their \pt and $\eta$ using the pre-calculated efficiency map.


\subsection{Sources of Systematic Uncertainties}\label{sec:sources_of_uncertainties}

This section briefly describes the different sources of uncertainty in the predictive model used in the analysis, and how each source of uncertainty is implemented within the analysis framework.
Considered sources of systematic uncertainty are listed in \cref{tab:sources_of_uncertainty}.
For each source of uncertainty, acceptance and shape uncertainties are derived.

\subsubsection{QCD Scales}
\begin{comment}
Perturbative QCD predictions for inelastic pp scattering depend on two scales that arise
when dealing with UV and IR divergencies: renormalization scale Î¼R and factorization scale Î¼F
The choice of these scales is arbitrary, to get a feeling for the dependence, the scales are
by convention varied usually by a factor 2 in both directions
\end{comment}
The \Vjets matrix element calculations contains infrared and ultraviolet divergences.
These are handled by introducing spurious parameters corresponding to the renomalisation scale ($\mu_R$) and factorisation scale ($\mu_F$).
Physical observables are not dependent on these parameters when using the infinite perturbation series expansion, however at some fixed order in QCD a limited dependence is present.
To assess the impact of this, both $\mu_R$ and $\mu_F$ are independently varied from their nominal values by factors of $0.5$ and $2$ to account for higher order corrections to the calculation of the matrix element used to simulate the process.

\subsubsection{PDF Sets}

Parton distribution functions (PDFs) specify the probability of finding a parton with a given momentum inside a hadron (in this case, inside colliding protons).
PDFs have to be derived from data and are a significant source of uncertainty in analyses of hadronic collision data.
There are three sources of PDF uncertainties: the statistical and systematic errors on the underlying data used to derive the PDFs, the theory which is used to describe them (which is based on some fixed order perturbative QCD expansion), and finally the procedure which is used to extract the PDFs from the data. 
PDF-related uncertainties were derived following \rcite{Butterworth:2015oua}.
This involves considering 100 PDF replicas which, when combined, form a central value and associated uncertainty, and also in parallel direct changes to the central values of PDFs using the MMHT2014 \cite{Harland-Lang:2014zoa} and CT14NLO \cite{Dulat:2015mca} PDF sets.

\subsubsection{Event Generator}

The choice of parton shower (PS) and underlying event (UE) generators can affect the analysis outcome.
Changing these models modifies several aspects of the event generation at the same time, such as the accuracy of matrix element predictions and different approaches to parton showering.
This change tends to lead to the largest disrepancy with respect to the nominal samples.

\subsubsection{Resummation and Merging Scales}

Resummation is a technique used in QCD to help cope with calculations involving disparate energy scales, and involves the introduction of an associated resummation scale, the choice of which introduces some systematic uncertainty into the model.
Parton showering models are accurate when simulating \lowpt radiation, however inaccuracies start to arrive when simulating hard emissions.
To combat this, parton showering models utilise more precise matrix element calculations above some momentum threshold.
The choice of threshold, or \textit{merging scale} introduces some uncertainty into the final result.
Resummation (QSF) and merging (CKKW) scale variations are available for a subset of the \textsc{Sherpa} samples.
The number of available events is significantly lower than the number of events in the nominal sample, and no statistically significant discrepancy with respect to the nominal samples is observed.
The corresponding uncertainties and therefore neglected.

\subsection{Implementation of Variations}\label{sec:implementation_of_variations}

Modelling variations are implemented in different ways, depending on the associated uncertainty.\cref{tab:sources_of_uncertainty} lists the different sources of uncertainty described in \cref{sec:sources_of_uncertainties} and for each lists the implementation.
%
\input{chapters/6.vhbb_boosted/tables/sources_of_uncertainty.tex}
%
As production of high-stastic MC samples is computationally expensive, a technique in state of the art simulation packages is to store some sources of variation as internal weights, which can be generated alongside the nominal samples, saving computation time.
The nominal sample then effectively contains information about an ensemble of different samples, corresponding to different model parameters, which are accessible via reweightings. 
When filling histograms for the variations, bins are incremented by the internal weight of the event associated with the variation in question.

While the inclusion of internal weight variation in MC event generators has decreased simulation times and increased available statistics, there are in \textsc{Sherpa 2.2.1} currently some sources of systematic uncertainty that are unable to be stored as internal weight variations due to technical limitations.
Two examples are the choice of resummation and merging scales.
A method to parameterise the systematic variation using one sample, and to then apply this parameterisation to another sample, has been developed by \ATLAS \cite{Anders:2125718}.
This method was used to derive resummation and merging uncertainties for the nominal \textsc{Sherpa 2.2.1} sample, using a previous (lower statistic) \textsc{Sherpa 2.1} alternative sample.
The resulting uncertainties were studied and found to be negligible in comparison with systematics from other sources.

\subsection{Vector Boson + Jets Modelling}\label{sec:vjets_modelling}

After event selection, the \Vjets background is a dominant background in all three analysis channels as described in \cref{sec:vebb_background_composition}.
The \Vjets samples are split into categories depending on the truth flavour of the track-jets which are ghost-associated to the \largeR jet Higgs candidate.
The categories are $V$+$bb$, $V$+$bc$, $V$+$bl$, $V$+$cc$, $V$+$cl$, $V$+$ll$, and $V$+hf refers collectively to the categories containing at least one $b$- or \cjet.
$V$+$bb$ is dominant generally accounting for \pct{80} of the jets, while $V$+hf accounts for around \pct{90} of jets.
The full flavour composition breakdown for each channel and analaysis region are given in \cref{tab:Wjets_0L_flavcomp,tab:Wjets_0L_flavcomp,tab:Zjets_0L_flavcomp,tab:Zjets_2L_flavcomp}.

In order to access uncertainties associated with the use of MC generators, variations of the data are produced using alternative generators or variation of nominal generator parameters as described in \cref{sec:implementation_of_variations}.
As described in \cref{sec:vhbb_samples}, the nominal MC event generator used for \Vjets events is \textsc{Sherpa 2.2.1}, while \textsc{MadGraph5\_aMC@NLO+Pythia8} (which uses a different parton showering model) is used as an alternative generator.

Modelling systematics can have several impacts, including affecting the overall normalisation for different processes, and the relative acceptances between different analysis regions (i.e. migrations between HP and LP SRs, between the SR and CR, and between \pTV bins), and the shapes of the \mJ distributions.
Since the fit model fits only the \largeR jet mass \mJ to data, all shape uncertainties are estimated with respect to this observable.
Several sources of uncertainty, summarised in \cref{sec:sources_of_uncertainties}, have been assessed.

\input{chapters/6.vhbb_boosted/tables/Wjets_0L_flavcomp.tex}
\input{chapters/6.vhbb_boosted/tables/Wjets_1L_flavcomp.tex}
\input{chapters/6.vhbb_boosted/tables/Zjets_0L_flavcomp.tex}
\input{chapters/6.vhbb_boosted/tables/Zjets_2L_flavcomp.tex}



\subsubsection{Acceptance Uncertainties}

Several different types of acceptance uncertainties have been calculated and implemented as nuisance parameters in the fit.
These account for uncertainty in the overall number of events in each channel, and for the migration of events between different analysis regions.
The acceptance uncertainties relevant to the \Vjets processes are summarised below.
%
\begin{itemize}
    \item \textbf{Overall normalisation:} only relevant where normalisation cannot be left floating (determined as part of the fit). The $V$+hf component is left floating in the fit. For other components, independent normalisations used for $W$+hf and $Z$+hf. The contributions are mainly determined by the 1-lepton (for $W$+hf) and 2-lepton (for $Z$+hf) SRs respectively and then extrapolated to 0-lepton channel.
    %
    \item \textbf{SR-to-CR relative acceptance:} the uncertainty on the normalisation of the signal region due to events migrating between the signal and control regions.
    %
    \item \textbf{HP-to-LP relative acceptance:} the uncertainty on the normalisation of the high-purity (HP) signal region due to events migrating between the high- and low-purity signal regions.
    %
    \item \textbf{Medium-to-high} \pTV \textbf{relative acceptance:} describes any shape effect in \pTV distribution, given that the analysis only uses two \pTV bins (medium and high).
    %
    \item \textbf{Flavour relative acceptance:} for each flavour $V$+$xx$, where $xx\in$ \{$bc$,$bl$,$cc$\} the ratio of $V$+$xx$/$V$+$bb$ events is calculated. This corresponds to the uncertainty of $Vbb$ events due to the miss-tagging of other flavours V$xx$.
    %variations in the ð‘‰ + ð‘ð‘/ð‘‰ + ð‘ð‘, ð‘‰ + ð‘ð‘™/ð‘‰ + ð‘ð‘ and ð‘‰ + ð‘ð‘/ð‘‰ + ð‘ð‘ ratios are accounte for independently for the ð‘Š- and ð‘-boson backgrounds.
    %
    \item \textbf{Channel relative acceptance:} corresponding to the uncertainty in the normalisation of \Vjets events events due to the migration of events between channels.
\end{itemize}
%
The uncertainties arising from the different sources described in \cref{sec:sources_of_uncertainties} are summed in quadrature to give a total uncertainty on each region.
A summary of the different acceptance uncertainties that were derived in this way and subsequently applied in the fit are given in \cref{tab:Vjets acceptance uncerts}.
An effort has been made, wherever possible, to harmonise similar uncertainties across different analysis regions and channels.

\input{chapters/6.vhbb_boosted/tables/V+jets-acceptance-uncertainties-summary.tex}

\subsubsection{Shape Uncertainties}

In order to derive shape uncertainties (which as the name suggests affect shapes but not overall normalisations of distributions), the following procedure is carried out.
Normalised distributions of the reconstructed \largeR Higgs candidate jet mass \mJ are compared for the nominal sample and variations.
For each variation, the ratio of the variation to nominal is calculated, the up and down variations are symmetrised, and an analytic function is fit to the symmetrised ratio.
If different analysis regions or channels show the same pattern of variation, a common uncertainty is assigned.
An example of a significant source of uncertainty, arising from choice of factorisation scale $\mu_R$ is shown in \cref{fig:Vjets_SysMUR}.
HP SRs split into medium and high \pTV bins are shown for the 0-lepton channel for \Whf and \Zhf jets.
The 0- and 1-lepton channels for the \Whf contribution and the 0- and 2-lepton channels for the \Zjets contribution are merged, since the shapes in \mJ are consistent across channels.
An exponential function $e^{p_0+p_1x}+p_2$ has been fitted to the ratio of the normalised distributions.
The magnitude of the variation does show \ptv dependence, and so two separate uncertainties are added in the fit, and applied individually in each \pTV region. 

The shape uncertainties for $\mu_R$ were derived on the SRs but are also applied to the CRs, as the low statistics in the CRs make it difficult to derive dedicated shape uncertainties.
All the shape uncertainties are fully correlated accross regions.

\begin{figure}[!htbp]
  \centering
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/0L_Whf_2tag1pfat0jet_250_400ptv_SR_noaddbjetsr_mJIncl_SysMUR.pdf}
    \caption{\Whf, HP SR, medium \pTV}
    \label{fig:Vjets_SysMUR_sub1}
  \end{subfigure}%
  \hfill
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/0L_Whf_2tag1pfat0jet_400ptv_SR_noaddbjetsr_mJIncl_SysMUR.pdf}
    \caption{\Whf, HP SR, high \pTV}
    \label{fig:Vjets_SysMUR_sub2}
  \end{subfigure}
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/0L_Zhf_2tag1pfat0jet_250_400ptv_SR_noaddbjetsr_mJIncl_SysMUR.pdf}
    \caption{\Zhf, HP SR, medium \pTV}
    \label{fig:Vjets_SysMUR_sub3}
  \end{subfigure}%
  \hfill
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/0L_Zhf_2tag1pfat0jet_400ptv_SR_noaddbjetsr_mJIncl_SysMUR.pdf}
    \caption{\Zhf, HP SR, medium  \pTV}
    \label{fig:Vjets_SysMUR_sub4}
  \end{subfigure}%
  \hfill
  \caption{Normalised leading \largeR jet mass distribution from \Zboson and \Whf processes in the HP SR of the \zlep channel. The renormalisation scale $\mu_r$ has been varied by a factor of 2 (1up) and 0.5 (1down). An exponential function is fitted to the ratio between the nominal and variation samples.}
  \label{fig:Vjets_SysMUR}
\end{figure}

A comparison of the \mJ shapes between \SHERPA and \MADGRAPH is shown in \cref{fig:Vjets_MGSherpa_inc}.
The plots are split by process and channel, but merged in SR purity and \ptv bins reflecting similarities between the \mJ shapes across these regions.
Due to the low statistics available for the alternate \MADGRAPH sample, and the lack of statistically significant variation between the samples, no associated shape uncertainty is added to the fit in this case. 

\begin{figure}[!htbp]
  \centering
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/0L_Whf_2tag1pfat0pjet_ptvinc_SR_noaddbjetsr_mJIncl.pdf}
    \caption{\Whf, \pTV inclusive SR, \zlep channel}
    \label{fig:Vjets_MGSherpa_inc_sub1}
  \end{subfigure}%
  \hfill
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/1L_Whf_2tag1pfat0pjet_ptvinc_SR_noaddbjetsr_mJIncl.pdf}
    \caption{\Whf, \pTV inclusive SR, \olep channel}
    \label{fig:Vjets_MGSherpa_inc_sub2}
  \end{subfigure}
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/0L_Zhf_2tag1pfat0pjet_ptvinc_SR_noaddbjetsr_mJIncl.pdf}
    \caption{\Zhf, \pTV inclusive SR, \zlep channel}
    \label{fig:Vjets_MGSherpa_inc_sub3}
  \end{subfigure}%
  \hfill
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/2L_Zhf_2tag1pfat0pjet_ptvinc_SR_mJIncl.pdf}
    \caption{\Zhf, \pTV inclusive SR, \tlep channel}
    \label{fig:Vjets_MGSherpa_inc_sub4}
  \end{subfigure}%
  \hfill
  \caption{The comparison on \mJ shapes between \SHERPA and \MADGRAPH samples
  from \Vhf process in \pTV inclusive signal regions.
  The Kolmogorov-Smirnov test and $\chi^2/ndf$ are shown on the plots.}
  \label{fig:Vjets_MGSherpa_inc}
\end{figure}


The impacts of variations in the factorisation scale $\mu_{F}$ and the choice of PDF set on \mJ shape were also found to be negligible in comparison with $\mu_{R}$ and are hence not associated uncertainty was added to the fit.


\subsection{Diboson Modelling}

The uncertainties for the diboson background generallys follows that of \Vjets.
However an alternative sample was generated using \textsc{Powheg} interfaced with \textsc{Pythia8}, using the AZNLO shower tune with the CTEQ6L1 PDFs \cite{Pumplin:2002:CTEQ6L1}.
Unlike \textsc{Sherpa}, \textsc{Powheg} models the off-shell $Z$ contribution at NLO.

Acceptance and shape uncertainties are derived in an analagous fashion to \Vjets.

\subsubsection{Acceptance Uncertainties}

Diboson acceptance uncertainties are summarised in \cref{tab:diboson_acceptance_uncerts}.
Variations from $\mu_R$, $\mu_F$, PDF choice and alternative generator are considered and are combined combined through a sum in quadrature as described in \cref{sec:vjets_modelling}.
The largest modification to the nominal acceptance results from the \textsc{Powheg+Pythia8} alternate sample, which modifies several parts of the generative model at the same time.
Since the diboson contribution to the \ttbar control region is small, no SR-to-CR relative acceptance uncertainty is required.

For the $WZ$ contribution, uncertainties are derived using the 1-lepton channel and applied to all three channels.
An additional \pct{8} channel migration uncertainty is applied on the 0-lepton channel.
For the $ZZ$ contribution, the normalisation uncertainty is calculated using the 2-lepton channel and applied to all three channels.
The 0- and 1-lepton channels have a similar HP-to-LP relative acceptance uncertainty of \pct{18}.
The 1-lepton medium-to-high \ptv relative acceptance is based off the value obtained from the 2-lepton channel.
\pct{30} and \pct{18} channel migration uncertainties are applied in the 0- and 1-lepton channels respectively.

Since the contribution from $WW$ is small, dedicated studies are not performed, but a \pct{25} normalisation uncertainty is applied in all the three channels which is based on the modelling studies performed for the previous analysis \cite{HIGG-2018-04}.

\input{chapters/6.vhbb_boosted/tables/VV_acceptance_uncertainties.tex}

\subsubsection{Shape Uncertainties}

Diboson shape uncertainties are derived in a similar fashion to \Vjets.
Only the uncertainties associated with systematic variation of $\mu_R$ and the event generator have a non-negligible impact on the \mJ shape.
Variation of $\mu_R$ produces consistent \mJ shape impacts across all regions and channels, and hence only a single associated uncertainty is derived, shown in \cref{fig:VV_muRFit}.
A hyperbolic tangent is fitted to the symmetrised ratio.

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=0.5\textwidth]{chapters/6.vhbb_boosted/figs/012L_VV_2tag1pfat0pjet_ptvinc_SR_noaddbjetsr_mJIncl_SysMUR.pdf}
  \caption{
    Normalised leading \largeR jet mass distribution from $WZ$ and $ZZ$ process, merged among all the signal regions and lepton channels.
    The renormalisation scale $\mu_R$ has been varied by a factor of 2 (1up) and 0.5 (1down).
    The red line shape shows the fitting results of the hyperbolic tangent function.
  }
  \label{fig:VV_muRFit}
\end{figure}

The comparison between the nominal \textsc{Sherpa} and alternative \POWPYTHIA8 samples is shown in \cref{fig:VV_PP8Fit} for the 0- and 1-lepton channels for both $WZ$ and $ZZ$ processes.
For these channels, the shape of \mJ varies in opposite directions in the LP and HP signal regions.
Shapes are similar between \ptv bins, the 0- and 1-lepton channels and for $WZ$ and $ZZ$.
A third order polynomial is fitted to the ratio, and this function transitions to a constant piecewise function in the high mass region to accurately represent the shape taking into account large statistical uncertainties.
Dependence on event generator was found to be negligible within statistical uncertainty in the 2-lepton channel.
All diboson shape uncertainties are fully correlated in the fit.

\begin{figure}[!htbp]
  \centering
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/01L_VV_2tag1pfat0jet_ptvinc_SR_noaddbjetsr_mJIncl_SysPwPy.pdf}
    \caption{High purity signal region}
    \label{fig:VV_PP8Fit_sub1}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/01L_VV_2tag1pfat1pjet_ptvinc_SR_noaddbjetsr_mJIncl_SysPwPy.pdf}
    \caption{Low purity signal region}
    \label{fig:VV_PP8Fit_sub2}
  \end{subfigure}
  \caption{
    The comparison on \mJ shapes between \SHERPA and \POWPYTHIA8 samples from $WZ$ and $ZZ$ process in high and low purity signal regions.
    \pTV regions and 0- and 1-lepton channels are merged.  
    The dashed green line shows the fitted third order polynomial function and the blue lines show the function after a protection is added in the high mass region.
  }
  \label{fig:VV_PP8Fit}
\end{figure}



\section{Statistcal Treatment}\label{sec:vhbb_fit}

Selected events are used to perform a statistical test of the background-only hypothesis, i.e. a model which does not include the \VHbb process.
The test involves a binned global maximum-profile-likelihood fit from the model to the data using the \mJ distribution, and combines all the analysis regions defined in \cref{tab:SR_CR_definition}.
The test is based on the profile likelihood ratio test statistic.
The signal strength $\mu = \sigma / \sigma_{\textnormal{SM}}$ is defined as the ratio between the observed and predicted cross-sections, where $\mu = 0$ corresponds to the background-only hypothesis and $\mu = 1$ corresponds to the SM prediction.
It is a parameter of interest (POI) which acts to scale the total number of signal events.

The present analysis makes use of two POIs.
The first, \muVH, is the signal strength for the \VHbb process, the primary process under investigation.
The diboson production strength \muVZ for the \VZbb process is measured simultaneously and provides a validation of the analysis apparatus used for the primary \Hbb measurement.
Alongside the two POIs, the predictive model depends on several uninteresting parameters which are not the primary target of measurement.
These parameters are called nuisance parameters (NPs), collectively referred to as $\theta$.
Freely floating background normalisations are implemented as NPs and are also extracted during the fitting processes.


\subsection{Likelihood Function}

The statistical setup treats each bin as a Poisson counting experiment and is based on the \textsc{RooStats} framework \cite{moneta2010roostats}.
The combined likelihood over $N$ bins is constructed as the product of Poisson probabilities in each bin.
Considering the simplified case of a single signal strength parameter $\mu$, and neglecting sources of systematic or statistical uncertainty, this is given by
%
\begin{equation}
    \mathcal{L}(\mu) = \prod_{i=1}^N \frac{(\mu s_i + b_i)^{n_i}}{n_i!} \exp \left[ - (\mu s_i + b_i) \right],
\end{equation}
%
where $s_i$ ($b_i$) is the expected number of signal (background) events in bin $i$, and $n_i$ is the number of observed data events in bin $i$.

\subsubsection{Treatment of Uncertainties}

Systematic uncertainties can modify the predicted signal and background yields $s_i$ and $b_i$. 
Each source of systematic uncertainty is taken into account by adding an additional NP $\theta_j$ to the likelihood in the form of a Gaussian cost function.
The combined effect of the NPs is then
%
\begin{equation}
  \mathcal{L}(\theta) = 
  \prod_{j = 1}^{N_\theta}
  \frac{1}{\sqrt{2 \pi \sigma_j}}
  \exp\left[ \frac{- (\overline{\theta}_j - \theta_j)^2}{2 \sigma_j^2} \right] ,
\end{equation}
%
where $N_\theta$ is the number of NPs, $\overline{\theta}_j$ is the nominal value of the $j$th NP, $\theta_j$ is the fitted value, and $\sigma_j$ is the corresponding associated prior uncertainty on $\theta_j$.
As the fitted value of the $\theta_j$ deviates from it's nominal value, a cost is introduced.
The presence of NPs modifies the likelihood as 
%
\begin{equation}
    \mathcal{L}(\mu) \rightarrow \mathcal{L}(\mu, \theta) = \mathcal{L}(\mu) \mathcal{L}(\theta) .
\end{equation}
%
The predicted signal and background yields are also modified by the presence of the NPs with
%
\begin{equation}
  s_i \rightarrow s_i(\theta) , \quad b_i \rightarrow b_i(\theta) .
\end{equation}
%
For NPs which are left freely floating in the fit, no corresponding Gaussian constraint is added to the liklihood.

Statstical uncertainty is also present, and implemented using a dedicated NP for each bin which can scale the background yield in that bin.
Statistical NPs are also implemented using a Gaussian constraint.

\subsubsection{Smoothing and Pruning}

Systematic uncertainties are smoothed and pruned in the fit.
Smoothing accounts for the large statistical uncertainty present in some bins that are subject to large fluctuations.
The smoothing procedure relies on the assumption that the impact of systematics should be approximately monotonic and correlated between neighbouring bins.

In addition to smoothing, pruning is the process of removing from the fit those systematics which only have a very small effect.
This improves the stability of the fit by reducing the number of degrees of freedom.
Acceptance uncertainties are pruned in a given region if they have a variation of less than \pct{0.5}, or if the up and down variations have the same sign in that region.
Shape uncertainties are pruned in a given region if the deviation in each bin is less than \pct{0.5} in that region.
In addition, acceptance and shape uncertainties are neglected in a given region for any background which makes up less than \pct{2} of the total background in a given region.


\subsubsection{Fit Procedure and Statistical Tests}

The best-fit value of $\mu$, denoted $\hat\mu$, is obtained via an unconditional maximisisation of the likelihood.
The likelihood is also used to construct a statistical test which can confirm or reject the background-only hypothesis.
The test statistic $q_\mu$ is constructed from the profile likelihood ratio, as in
%
\begin{equation}
  q_\mu = -2 \ln \frac{\mathcal{L(\mu, \hat{\hat{\theta}}_\mu )} } { \mathcal{L(\hat{\mu}, \hat{\theta}}) }
\end{equation}
%
where $\hat{\mu}$ and $\hat{\theta}$ are chosen to maximise the likelihood $\mathcal{L}$, and the profile value $\hat{\hat{\theta}}_\mu$ is obtained from a conditional maximisation fo the likelihood for a specific choice of $\mu = 0$ corresponding to the background-only hypothesis.
% i.e. this is the profile likelihood (double hat term)

The test statistic is used to construct a $p$-value which is used to confirm or accept the background-only hypothesis.
The $p$-value is typically reported in terms of the significance $Z$, defined as the number of standard deviations for a Gaussian Normal distribution which will produce a one-sided tail integral equal to the $p$-value, as in
%
\begin{equation}
  p = \int_Z^{\infty} \frac{1}{\sqrt{2 \pi}} e^{-x^2/2} ~\mathrm{d} x
  = 1 - \Phi(Z) .
\end{equation}
%
Typically a value of $Z=3$ constitues \textit{evidence} of a processes, while $Z=5$ is required for a \textit{discovery}.
Alongside the $p$-value, the best-fit value of the signal strength $\hat\mu$ and its corresponding uncertainty are typically quoted, and compared to their expected values (see \cref{sec:fit_expected}).

\begin{comment}
  All initial background distribution shapes prior to the fit (described in Section 8), except those for multÄ³et, are estimated from the samples of simulated events. The multÄ³et shape and normalisation are determined using data  
  The normalisation on the diboson background is left floating in the fit, i.e. measured simultaneously along with the $VH$ signal
\end{comment}


\subsection{Background Normalisations}

The normalisation of the largest backgrounds are left floating and are determined in the fit.
The corresponding postfit background normalisations are listed in \cref{tab:bkg_norms}.
A single normalisation factor is used for \Whf and \Zhf, which constitue more than \pct{90} of the total \Vjets background, since the use of independent factors in different channels were found to be compatible.

\input{chapters/6.vhbb_boosted/tables/bkg_norms.tex}

The normalisations and shapes of all other backgrounds, with the exception of the multijet background which is estimated using a data driven technique, are initialised using the simulated samples.


\subsection{Asimov Dataset \& Expected Results}\label{sec:fit_expected}

The Asimov dataset is constructed by replacing the data with the sum of the signal and background predictions $n_i = s_i + b_i$.
A fit to this dataset using the nominal values of the NPs from the simulation will recover the input values and is useful for studying constraints on and correlations between the NPs.

Alternatively, a conditional fit to the Asimov dataset can be performed using values of the background NPs which are determined from an unconditional fit to data.
The signal NPs and POIs are fixed at their nominal values from the SM simulation.
The result of this fit can be used to calculate expected (median) significances, which can be compared to their observed values.
%The fit is conditional on the signal strength parameter, which is fixed at its nominal value.

\section{Results}\label{sec:vhbb_results}

In the present analysis, the two signal strength parameters \muVH and \muVZ are extracted from a simultaneous maximisation of the likelihood described in \cref{sec:vhbb_fit}.
The results of the analysis are summarised in this section.
Post-fit \mJ distributions are shown in \cref{sec:postfit_plots}.
The observed signal strengths are given in \cref{sec:signal_strengh_sigs}, along with observed and expected significances.
Finally in \cref{sec:sys_results} the impact of systematic uncertainties on the results is examined.


\subsection{Post-fit Distributions}\label{sec:postfit_plots}

In addition to the observed significance and signal strength, it is also useful to study the post-fit \mJ distributions to compare the simulation and data using the best-fit values $\hat{\mu}$ and $\hat{\theta}$.
Post-fit \mJ distributions are given for the signal regions in the 0-, 1- and 2-lepton channels in \cref{fig:vhbb_postfit_plots}.
The LP and HP regions are merged for the 0- and 1-lepton channels.
The plots show large falling backgrounds, predominantly made up of \Wjets and Z+jets events, and a signal distribution corresponding to the Standard Model Higgs boson peaking around $m_H = 125$ GeV.
In general there is a good level of agreement between the simulation and data, indicating the fit model is performing as expected.
\cref{fig:vhbb_postfit_plots_cr} shows the post-fit plots for the \ttbar control regions.
Again, a good level of agreement is observed given the statistical uncertainties on the distributions.

\begin{figure}[!htbp]
  \centering
  \begin{subfigure}{.4\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/Region_BMin250_BMax400_incFat1_Fat1_Y6051_DSRnoaddbjetsr_T2_L0_distmBB_GlobalFit_unconditionnal_mu1.pdf}
  \end{subfigure}%
  \begin{subfigure}{.4\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/Region_BMin400_incFat1_Fat1_Y6051_DSRnoaddbjetsr_T2_L0_distmBB_GlobalFit_unconditionnal_mu1.pdf}
  \end{subfigure}
  \begin{subfigure}{.4\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/Region_BMin250_BMax400_incFat1_Fat1_Y6051_DSRnoaddbjetsr_T2_L1_distmBB_GlobalFit_unconditionnal_mu1.pdf}
  \end{subfigure}%
  \begin{subfigure}{.4\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/Region_BMin400_incFat1_Fat1_Y6051_DSRnoaddbjetsr_T2_L1_distmBB_GlobalFit_unconditionnal_mu1.pdf}
  \end{subfigure}
  \begin{subfigure}{.4\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/Region_distmBB_J0_L2_T2_DSR_Y6051_incJet1_Fat1_incFat1_BMin250_BMax400_GlobalFit_unconditionnal_mu1.pdf}
  \end{subfigure}%
  \begin{subfigure}{.4\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/Region_BMin400_incFat1_Fat1_incJet1_Y6051_DSR_T2_L2_distmBB_J0_GlobalFit_unconditionnal_mu1.pdf}
  \end{subfigure}
  \caption{
    The \mJ post-fit distributions
    in (top) the 0-, (middle) 1- and (bottom) \tlep SRs for
    (left) $\SI{250}{\GeV} < \ptv < \SI{400}{\GeV}$ and (right) $\ptv \geq \SI{400}{\GeV}$. The LP and HP regions are merged for the \zlep and \olep channels.
    The fitted background contributions
    are shown as filled histograms. The Higgs boson signal ($m_H =
    \SI{125}{\GeV}$) is shown as a filled histogram and is 
    normalised to the signal yield extracted from data
    ($\muVH = 0.72$), and as an unstacked unfilled histogram,
    scaled by the SM prediction times a factor of two. The size of the
    combined on the sum of the
    fitted signal and background is shown in the hatched band. The
    highest bin contains the overflow. 
    %The ratio of the data to the sum of the fitted signal and background is shown in the lower panel.
    %Post-fit distributions for the 0-lepton (left) and 2-lepton (right) channels in the high purity medium \pTV region, obtained in the combined conditional $\mu=1$ fit to data. The last bin of each plot is an overflow bin.
  }
  \label{fig:vhbb_postfit_plots}
\end{figure}


\begin{figure}[!htbp]
  \centering
  \begin{subfigure}{.4\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/Region_distmBB_J0_L0_T2_DSRtopaddbjetcr_Y6051_incJet1_Fat1_incFat1_BMin250_BMax400_GlobalFit_unconditionnal_mu1.pdf}
  \end{subfigure}%
  \begin{subfigure}{.4\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/Region_distmBB_J0_L1_T2_DSRtopaddbjetcr_Y6051_incJet1_Fat1_incFat1_BMin250_BMax400_GlobalFit_unconditionnal_mu1.pdf}
  \end{subfigure}
  \begin{subfigure}{.4\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/Region_BMin400_incFat1_Fat1_incJet1_Y6051_DSRtopaddbjetcr_T2_L0_distmBB_J0_GlobalFit_unconditionnal_mu1.pdf}
  \end{subfigure}%
  \begin{subfigure}{.4\textwidth}
    \includegraphics[width=\textwidth]{chapters/6.vhbb_boosted/figs/Region_BMin400_incFat1_Fat1_incJet1_Y6051_DSRtopaddbjetcr_T2_L1_distmBB_J0_GlobalFit_unconditionnal_mu1.pdf}
  \end{subfigure}
  \caption{
    The \mJ post-fit distributions in the \ttbar control region for
    (top) the \zlep channel and the \olep channel for $\SI{250}{\GeV} < \ptv < \SI{400}{\GeV}$ and (bottom) the \zlep\ channel and the \olep\ channel for $\ptv > \SI{400}{\GeV}$.
    The background
    contributions after the likelihood fit are shown as filled
    histograms. The Higgs boson signal ($\mh = \SI{125}{\GeV}$) is shown as a
    filled histogram on top of the fitted backgrounds normalised to the
    signal yield extracted from data ($\mu_{VH}^{bb}=0.72$), and
    unstacked as an unfilled histogram, scaled by the SM prediction times a factor 
    of 2. The size of the combined statistical and systematic
    uncertainty for the sum of the fitted signal and background is
    indicated by the hatched band. The highest bin in the distributions
    contains the overflow.
  }
  \label{fig:vhbb_postfit_plots_cr}
\end{figure}


\subsection{Observed Signal Strength \& Significance}\label{sec:signal_strengh_sigs}

The measured signal strength is computed as the ratio between the measured signal yield to the prediction from the SM.
The combed result for all three lepton channels and all analysis regions is given for \muVH in \cref{eq:muVH}, and for \muVZ is given in \cref{eq:muVZ}.
Both results include a full breakdown of the systematic and   statistical uncertainties.
%
\begin{equation}\label{eq:muVH}
  \muVH = 0.72 ^{+0.39}_{-0.36} = 0.72 ^{+0.29}_{-0.28}  \mathrm{(stat.)} ^{+0.26}_{-0.22} \mathrm{(syst.)}
\end{equation}
%
\begin{equation}\label{eq:muVZ}
  \muVZ = 0.91 ^{+0.29}_{-0.23} = 0.91 \pm 0.15 \mathrm{(stat.)} ^{+0.24}_{-0.17} \mathrm{(syst.)} 
\end{equation}
%
The results for \muVH and \muVZ agree with the expectation from the SM within their combined uncertainty.
The \muVH measurement is dominated by statistical uncertainty, while the \muVZ measurement is dominated by systematic sources of uncertainty.
These measured signal strength for \muVZ corresponds to an observed significance of 2.1 standard deviations, with an expected (median) significance given the SM prediction of 2.7 standard deviations obtained using the method described in \cref{sec:fit_expected}.
The diboson observed (expected) signal strength significance is 5.4 (5.7).
These results are summarised in \cref{fig:money_plot}, which shows the background-subtracted \mJ distribution.
A clear signal excess is visible around the Higgs mass of $m_H = \SI{125}{\GeV}$.

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=0.5\textwidth]{chapters/6.vhbb_boosted/figs/Region_BMin250_incFat1_Fat1_incJet1_Y6051_DSRnoaddbjetsr_T2_L3_distmBB_Higgsweighted_BkgSub_GlobalFit_unconditionnal_mu1.pdf}
  \caption{
    \mJ distribution in data after subtraction of all backgrounds except for the $WZ$ and $ZZ$ diboson processes. The contributions from all lepton channels and signal regions are summed and weighted by their
    respective values of the ratio of fitted Higgs boson signal and
    background yields. The expected contribution of the associated $WH$
    and $ZH$ production of a SM Higgs boson with $m_H = \SI{125}{\GeV}$ is
    shown scaled by the measured combined signal strength
    ($\muVH=0.72$). The diboson contribution is normalised to its
    best-fit value of $\muVZ=0.91$. The size of the combined
    statistical and systematic uncertainty is indicated by the hatched
    band. This error band is computed from a full signal-plus-background
    fit including all the systematic uncertainties defined in
    \cref{sec:vhbb_modelling}, except for the $VH/VZ$
    experimental and theory uncertainties.  
  }
  \label{fig:money_plot}
\end{figure}

\subsubsection{Compatability Studies}

Alongside the standard 2-POI fit, a (3+1)-POI fit can be performed by splitting \muVH into three separate POIs, one for each channel.
A simultaneous fit to the channel specific signal strengths can then be performned, which allows a comparison of the contributions from each channel.
\cref{fig:channel_comp} compares the best-fit signal strengths.
The 0- and 1-lepton channels show a signal strength which is consistent with the SM prediction, while the 2-lepton channel shows a small deivation within the $1\sigma$ uncertainty.
Overall, good compatibility is observed via a $\chi^2$ test with a corresponding $p$-value of \pct{49}.

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=0.7\textwidth]{chapters/6.vhbb_boosted/figs/Plot_mu_102_VH.pdf}
  \caption{
    Signal strength compatibility test between the (3+1)-POI fit (with the three lepton channels splitted) and the default (1+1)-POI fit. The compatibility of the three channels is evaluated via a $\chi^2$ difference test and results in a p-value of \pct{49}.
  }
  \label{fig:channel_comp}
\end{figure}



\subsection{Impact of Systematics}\label{sec:sys_results}

The impact of systematic uncertainties on the final fitted value \muhatVH is studied looking at the NP rankings, and the uncertainty breakdown.

\cref{fig:np_ranking} shows the NP ranking, which is used to visualise which out of the many NPs involved in the fit have the largest impact on the sensitivity to the fitted POI.
To obtain the ranking, a likelihood scan is performed for each NP $\theta_j$.
First, an unconditional fit is used to determine $\hat{\theta}_j$.
From this best-fit point, the NP is varied in steps and the likelihood is recomputed until the $\pm 1 \sigma_{\hat{\theta}_j}$ values are reached.
For each corresponding value of $\theta_j$, the change in the best-fit value of the POI, $\Delta \muhatVH$ is calculated and used to rank the NPs.
Also shown in \cref{fig:np_ranking} are the pulls and constraints for the highest ranked NPs.

The experimental uncertainty on the signal \largeR jet mass resolution (JMR) has the largest impact of any NP.
It is a significant contributor to the overall uncertainty on \muVH in \cref{eq:muVH}.
JMR and jet energy scale (JES) uncertainties also have impacts for the \Vjets background and for the diboson background.
The freely-floating \Zhf normalisation is the second highest ranked NP, and is heavily constrained by the fit.
The $VZ$ POI \muVZ is also a significant NP when considering the primary \muVH measurement.

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=0.7\textwidth]{chapters/6.vhbb_boosted/figs/Ranking_VH_Observed.pdf}
  \caption{
    Impact of systematic uncertainties on the fitted $VH$ signal-strength parameter \muVH sorted in decreasing order.
    The boxes show the variations of $\hat{\mu}$, referring to the top $x$-axis, when fixing the corresponding individual nuisance parameter to its post-fit value modified upwards or downwards by its post-fit uncertainty, i.e. $\hat{\theta} \pm \sigma_{\hat{\theta}}$, and repeating the fit.
    The impact of up- and down-variations can be distinguished via the dashed and plane box fillings.
    The yellow boxes show the pre-fit impact (top $x$-axis) by varying each nuisance parameter by $\pm 1$. The filled circles show the deviation of the fitted value for each nuisance parameter, $\hat{\theta}$, from their nominal input value $\theta_0$ expressed in standard deviations with respect to their nominal uncertainties $\Delta \theta$ (bottom $x$-axis).
    The error bars show the post-fit uncertainties on $\hat{\theta}$ with respect to their nominal uncertainties.
    The open circles show the fitted values and uncertainties of the normalization parameters that are freely floating in the fit.
    Pre-fit, these parameters have a value of one.
  }
  \label{fig:np_ranking}
\end{figure}

The NP ranking highlights individual NPs which have a large impact on the POI measurement sensitivity.
Complementary information is provided at a higher level by considering the overall impact of different groups of systematics.
The groups are constructed from NPs which have similar physical origin.
The results are provided in \cref{tab:mu_syst_unc}.

\begin{comment}
 First, the nominal fit is run and the uncertainty on the
PoI ÏƒÂµË† is extracted via a likelihood scan. Then, for each group g an additional fit
is run with all NPs from the group fixed to their central values. The uncertainty
on the PoI from this fit, Ïƒ
g
ÂµË†
, is then subtracted in quadrature from ÏƒÂµË† to obtain
\end{comment}
\input{chapters/6.vhbb_boosted/tables/mu_systs.tex}



\section{Improved \texorpdfstring{\btagging}{b-tagging} using GNNs}


\section{Conclusion}

Work has been carried out as part of the boosted VHbb analysis group to understand, and implement in the global profile likelihood fit, systematic uncertainties on \Vjets samples. This background modelling work is an essential part of the success of the analysis. So far the fit has proved stable with the inclusion of the \Vjets uncertainties, and detailed studies are now underway to determine the causes behind any observed pulls of the added NPs. Additional work is ongoing to help with the derivation of uncertainties on diboson samples, another important background. The analysis is already advanced, and is now progressing into its final stages. Publication is expected in the new year.

This analysis would benefit greatly from the improved high \pt \btagging enabled by \GNN.
