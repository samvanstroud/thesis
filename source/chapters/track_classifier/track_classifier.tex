\chapter{Track Classification MVA}\label{chap:track_classification_mva}

The chapter details work on implementing a multivariate algorithm (MVA) to predict the truth origin of reconstructed tracks.
An introduction to formalisms of machine learning is given in \cref{sec:ml_background}.
In \cref{sec:track_labelling}, the truth origin label is defined, and in \cref{sec:fake_track_mva} these labels are used to train a machine learning model that can effectively discriminate between good and fake tracks.
Several studies motivated this work by demonstrating that at high \pt, \btagging performance was degraded by the presence of large numbers of poorly reconstructed or fake tracks.
If an algorithm could be trained to detect fake tracks, these could be removed before their input to the \btagging algorithms with the aim of improving performance.


\section{Machine Learning Background}\label{sec:ml_background}

Over the past few decades, machine learning (ML) techniques have become increasingly popular in high energy physics experiments due the increased volumes of high-dimensional data and improvements in the field of machine learning (in particular deep learning).
Machine learning is the process in which a computer program uses data to learn suitable parameters for a predictive model model.
This is opposed to explicitly providing instructions on how to perform a task.
A subfield known as \textit{supervised learning} is used in this work, and consists of exposing a model to a large number of labelled examples in order to extract relationships between the input data and their labels.
These relationships are often complex, and explicitly programmed rules can fail to fully capture the relationships between inputs and outputs.

%The field of machine learning aims to design computer programs which, rather than being programmed explicitly with instructions on how to perform a specific task, instead learn from a set of labelled training examples $S_i$ how to perform the task for themselves, essentially replacing the need to manually design a program to perform a specific task.
%In this section a subset of machine learning techniques called supervised learning is described.

In the simplest case, a set of $m$ labelled training examples $S = \{ (x_1, y_1) , \ldots , (x_m, y_m) \}$ is collected.
Each element $(x_i, y_i)$ consists of a input vector $x_i  \in \mathbb{R}^{\textnormal{input}}$, and the corresponding label $y_i$.
In classification problems, these labels are integer \textit{class labels} $y_i \in \{0,\ldots,N-1\}$, where $N$ is the number of classes, which specify which of a pre-determined set of categorical classes the training example belongs to.
The rest of the discussion in this chapter is limited to binary classification problems ($N = 2$).
The two classes are often referred to as signal ($y_i = 1$) and background ($y_i = 0$), which need to be separated.
Collecting sufficient and suitable data is one of the primary challenges of machine learning, as such data is not always readily available.
Fortunately, sophisticated tools to simulate particle collisions have already been developed by the scientific community \cite{leshouchesaccords, leshouchesstandardisation}.
These tools play a key role in generating a suitablly large amount of labelled data which is used to train algorithms.
More detail on the input datasts is given in \cref{sec:track_classifier_datasets}.

After obtaining suitable training data, the next step is to define a model.
Given an input domain $\mathbb{R}^{\textnormal{input}}$ and an output domain $(0, 1)$, the model
$f_\theta: \mathbb{R}^{\textnormal{input}} \to (0, 1)$ is a parameterised functional mapping from input space to output space.
Given an input example $x_i$ and a set of parameters $\theta$, the model outputs a prediction $\hat{y}_i \in (0, 1)$ for the true label $y_i$, as in
%
\begin{equation}
    f_\theta(x_i) = \hat{y}_i .
\end{equation}
%
The output $\hat{y}_i$ is in the interval $(0, 1)$ so as to be interpreted as the probability that the input example $x_i$ belongs to the signal class.
The parameters $\theta$ of the model are randomly initialised, however the model is designed to be expressive enough to correctly map the inputs $x_i$ to the outputs $y_i$ given the correct choice of parameters.
The model is then trained, which amounts to showing the model a series of labelled training examples and modifying the parameters of the model based on its performance.


\subsection{Neural Networks}\label{sec:neural_nets}

Neural networks (NNs) are a common choice for the machine learning model $f$ since they have the ability to approximate any function \cite{HORNIK1989359} and are easy to train via backpropagation \cite{rumelhart1986learning}.

\subsubsection{Artificial Neurons}

The basic functional component of a NN is the \textit{artificial neuron} or node, which is loosely inspired by a mathematical model of a biological neuron \cite{mcculloch1943logical, hopfield1987neural}.
An artificial neuron is defined by its parameters or \textit{weights} $\theta$ and a choice of activation function.
Each neuron takes a fixed number of inputs and computes the dot product of the input and weight vectors $x^T \theta$ and additionally adds a constant bias term $\theta_0$.
This term plays the role of a trainable constant value that is independent of the inputs.

\begin{figure}[!htbp]
    \centering
    \input{chapters/track_classifier/figs/neuron.tex}
    \caption{
      A diagram displaying the logical flow of a single neuron with three inputs $x_i^j$.
      Each input is multiplied by a weight $\theta_j$, and the resulting values are summed.
      A bias term $\theta_0$ is added, and the result is passed to an activation function.
      Each neuron can be thought of as a logistic regression model.
    }
    \label{fig:neuron}
\end{figure}

The dot product is fed into an activation function $g$.
The activation function has several uses, most notably acting as a source of non-linearity and bounding the output of the neuron.
Some common activation functions are shown in \cref{fig:activation_functions}.
The choice of activation function can have implications for the performance and convergence of the network, since the gradient of $g$ is used to compute the weight updates during training.
This is also why input data is normalised to have zero mean and unity variance \cite{lecun2012efficient}.

\begin{figure}[!htbp]
  \centering
  \input{chapters/track_classifier/figs/activations.tex}
  \caption{
    Several common choices for the activation function $g$ of an artificial neuron.
  }
  \label{fig:activation_functions}
\end{figure}


\subsubsection{Networks}

Several neurons are linked together in layers to form a neural network.
The inputs are propagated layer-by-layer through the network until reaching the final output layer.
The number of layers and neurons per layer are important hyperparameters (those parameters which are not optimised as part of the training process) which influence the performance of the model.
In the case of binary classification, the final output layer consists of a single neuron with a sigmoid activation 
%
\begin{equation}\label{eq:sigmoid}
  g(z) = \frac{1}{1 + e^{-z}} ,
\end{equation}
%
which is bounded between zero and one allowing the final output to be interpreted as the probability that the input sample belongs to the signal class.
NNs have the crucial property of being differentiable functions, which facilitates training process described in the next section.

%The activation $a_i^{(l)}$ is the output of the activation function $g(z)$ of the $i^{\text{th}}$ node in layer $l$. The tensor element $\Theta_{ji}^{(l)}$ is the weight connecting the $i^{\text{th}}$ node in layer $l - 1$ to the $j^{\text{th}}$ node in layer $l$. We can compute the outputs for each neuron in a layer simultaneously using ${a}_j^{(l)} = g(\Theta_{ji}^{(l)} a_i^{(l-1)})$, where the activation function is computed element wise on the vector. Computers can perform matrix operations in parallel, making a vectorised implementation such as this more efficient than calculating each output sequentially.

%Taking an item from the dataset $S$, $(\mathbf{x}_i, {y}_i)$, the input $\mathbf{x}_i$ is propagated through the network from left to right, one layer at a time. Finally, the classification result of the network, given by the output of the final neuron $\hat{\mathrm{y}} = h(\mathbf{x}_i)$, is obtained and can be compared to the true category of the data $\mathrm{y}_i$. 



\subsection{Training with Gradient Descent}\label{sec:training_sgd}

A training algorithm is used to optimise the weights of a NN after exposure to the training data.
%The performance of the trained model depends on the amount and quality of the training data, and the efficacy of the training algorithm.
The training algorithm works minimising a loss function $L$, which quantifies the error in the model's predictions for a given input.
NNs are commonly trained using backpropagation in combination with a variant of stochastic gradient descent to iteratively update the model parameters.
In binary classification problems, the binary cross entropy given in \cref{eq:bce_loss} loss if often used.
%
\begin{equation}\label{eq:bce_loss}
  L(x_i, \theta) = y_i \ln[f_\theta(x_i)] + (1 - y_i) \ln[1 - f_\theta(x_i)]
\end{equation}
%
Since the model $f$ is differentiable, the error for each parameter $\theta_i$ can be computed by taking partial derivative of $L$ with respect to the parameter.
Updated parameters $\theta_i'$ are calculated by updating the original parameter in the direction which reduces the loss.
%
\begin{equation}\label{eq:weight_update}
  \theta_i' = \theta_i - \alpha \pd{L}{\theta_i}
\end{equation}
%
The hyperparameter $\alpha$ is known as the \textit{learning rate} and dictates the size of the step taken in the direction of the slope. 
The errors for each parameter are efficiently calculated using the backpropagation algorithm.
The process of updating weights is repeated until the weights converge the network is trained.
In practice, small batches of the input data are shown to the network at a time. For each batch the average loss is calculated and the network's weights are updated.
There are many extensions and variations of the gradient descent algorithm.
This work uses the Adam optimiser which adds momentum to the weight updates (dampening oscillations) and an adaptive per-parameter learning rate \cite{2014arXiv1412.6980K}.

\begin{comment}
The gradient descent (\cref{sec:backprop_sgd}) algorithm is used to fit the model to the data.
Using \cref{eq:bce_loss}, an error for 
From \cref{eq:bce_loss}, the error on the output node can be 
The error for the final output node is computed first.
Errors for nodes in the previous layers are computed by \textit{backpropagating} this error through the network.
The error in the output node can be computed explicitly using the loss function in \cref{eq:bce_loss}.
To find the errors for the nodes in the preceding layers $\delta^{(L-1)}_i$, we need to differentiate eq. \ref{neural cost} with respect to $z^{(L-1)}_i$.
In order to perform the differentiation, we relate $z_1^{(L)} = g(z_j^{(L-1)}) \Theta_{1j}^{(L)}$.
The result,is tantamount to propagating the output error back through the network using the weights, and multiplying at each node by the derivative of the activation function. Once the errors have been propagated through the network, the partial derivatives of $J$ can be found using the final expression in eq. \ref{backprop defs}. Lastly the weights are updated simultaneously using eq. \ref{update weights}. 

gradient descent is an example of an \textit{optimisation} algorithm that minimises the cost function $J(\theta)$ (thereby fitting the logistic regression model discussed above to some data) by selecting the optimal values of $\theta$. The algorithm works by computing the partial derivatives of $J(\theta)$ with respect to the parameters $\theta$. The parameters are then altered slightly in the direction of decreasing slope, thereby reducing the cost function.
%The partial derivative of the loss function can be calculated for every parameter $\theta_i$ in the model.

The above step must be performed simultaneously for each $\theta_j$ in $\theta$, after which a new value of $J(\theta)$ can be calculated, and the process repeated. We can compute the partial derivatives of $J$ using the derivative of the logistic function from eq. \ref{eq:bce_loss}. The results are substituted into \cref{eq:weight_update} to obtain
\end{comment}





\section{Track Truth Origin Labelling}\label{sec:track_labelling}

Crucial to supervised learning techniques are are the ground truth class labels which the machine learning model is trained to predict.
A set of track truth labels which a high degree of granularity have been implemented in the \ATLAS software stack, and are listed in \cref{tab:truth_origins}.
The labelling scheme has designed to be useful beyond the classification of good and fake tracks.
The origins are determined by analysing the detailed simulated truth record for the truth particle associated with each track.
Tracks are associated with truth particles by selecting the truth particle with the highest \textit{truth-matching probability} (TMP), defined in \cref{eq:tmp_def}.
This is a weighted sum of the number of hits on a track which are from the same truth particle, versus the total number of hits on the track.
The weights are subdetector-dependent are designed to account for the varying number of layers in each of the subdetectors.
%
\begin{equation}\label{eq:tmp_def}
    \textnormal{TMP} = 
    \frac{
        10 N_{\textnormal{Pix}}^{\textnormal{good}} + 
        5  N_{\textnormal{SCT}}^{\textnormal{good}} + 
           N_{\textnormal{TRT}}^{\textnormal{good}}
        }{
        10 N_{\textnormal{Pix}}^{\textnormal{all}} + 
        5  N_{\textnormal{SCT}}^{\textnormal{all}} + 
            N_{\textnormal{TRT}}^{\textnormal{all}}
        }
\end{equation}
%
For the fake track classification tool, the origins in \cref{tab:truth_origins} are used to construct a binary label by labelling all fake tracks background, and all other tracks as signal.
The fake track classifier is then trained to distinguish between these two categories of tracks.
Fake tracks are also defined using the TMP, with a $\textnormal{TMP} < 0.5$ giving a track the label of fake.
Fake tracks are made up of combinatorial fakes, which are tracks which do not correspond to the trajectory of any truth particle, and poorly reconstructed tracks, which may somewhat resemble the trajectory of a truth particle but may be off due to the presence of some wrong hits on the track.

\begin{table}[!htbp]
    \footnotesize\centering
    \setlength{\tabcolsep}{0.5em} % for the horizontal padding
    \begin{tabular}{lll}
        \toprule\hline
        \textbf{Truth Origin} & \textbf{Description} \\
        \hline
        Pileup  & From a \pp collision other than the primary interaction \\
        Fake    & Created from the hits of multiple particles \\
        Primary & Does not originate from any secondary decay \\
        fromB   & From the decay of a \bhadron \\
        fromBC  & From a \chadron decay which itself is from the decay of a \bhadron \\
        fromC   & From the decay of a \chadron which is not from teh decay of a \bhadron \\
        %fromTau & From the decay of a $\tau$ \\
        OtherSecondary & From other secondary interactions and decays \\
        \hline\bottomrule
    \end{tabular}
    \caption{
      Truth origins which are used to categorise the physics process that led to the production of a track.
      Tracks are matched to charged particles using the truth-matching probability~\cite{PERF-2015-08}.
      A truth-matching probability of less than $0.5$ indicates that reconstructed track parameters are likely to be mismeasured and may not correspond to the trajectory of a single charged particle.
      The ``OtherSecondary'' origin includes tracks from photon conversions, \Kshort and $\Lambda^0$ decays, and hadronic interactions.
    }
    \label{tab:truth_origins}
\end{table}

\section{Fake Track Identification Tool}\label{sec:fake_track_mva}

The rate of fake tracks increases at high transverse momentum as shown in \cref{fig:fakerate_vs} due to the difficulties in track reconstruction outlined in \cref{sec:b_track_reco_challenges}.
The performance of \btagging algorithms is reduced as a direct result of the presence of these fake tracks as shown for SV1 in \cref{fig:sv1_perf_nofake}.

To identify and remove fake tracks, a NN classification tool was trained with good tracks as the signal class and fake tracks as the background class.
Due to the imbalance between the two classes (with fake tracks being relatively uncommon), a weight was added to the loss function for the background class to account for this.
The NN was made up of two hidden layers with 100 nodes per layer. 
The ReLU activation function was used in conjunction with the Adam optimiser with a learning rate of $1\text{e}{-3}$.
Optimisation of the networks architecture has been carried out to ensure good performance without a relatively small number of learnable parameters.
The model was trained using \num{40} million tracks with a futher \num{1} million tracks each used for validation and testing.

\begin{figure}[!htbp]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
      \centering
      \includegraphics[width=\textwidth]{chapters/track_classifier/figs/fakerate_vs_pt.pdf}
  \end{subfigure}
  \quad
  \begin{subfigure}[b]{0.48\textwidth}
      \centering
      \includegraphics[width=\textwidth]{chapters/track_classifier/figs/fakerate_vs_dr.pdf}
  \end{subfigure}
  \caption{
    Rate of fake tracks as a function of jet transverse momentum (left) and $\DeltaR(\textnormal{track}, \textnormal{jet})$ (right).
    The rate of fake tracks increases significantly as a function of \pt, and also increases as the distance to the jet axis decreases, and the number of tracks in the jet increases (not shown).
  }
  \label{fig:fakerate_vs}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{chapters/track_classifier/figs/sv1_perf_nofake.pdf}
    \caption{
      The \ljet efficiency of the low level tagger SV1 as a function of \bjet efficiency for the nominal tracking setup (black) and for the case where fake tracks which are not from the decay of a \bhadron are removed.
      The \ljet efficiency is decreased, demonstrating that the presence of fake tracks is detrimental to algorithm performance.
    }
    \label{fig:sv1_perf_nofake}
\end{figure}

Inputs to the model are described in \cref{sec:fake_mva_model_inputs}, while fake track removal performance is given in \cref{sec:fake_track_mva_results}.

\subsection{Datasets}\label{sec:track_classifier_datasets}

To train and evaluate the model, simulated SM \ttbar and BSM \Zprime events initiated by proton-proton collisions at a center of mass energy $\sqrt{s} = \SI{13}{\TeV}$ are used.
The \Zprime sample is constructed in such a manner that it has a relatively flat jet \pt spectrum up to \SI{5}{\TeV} and decays to an equal numbers of \bcl jets.
The generation of the simulated event samples includes the effect of multiple $pp$ interactions per bunch crossing with an average pileup of $\langle \mu \rangle = 40$, which includes the effect on the detector response due to interactions from bunch crossings before or after the one containing the hard interaction.

\newcommand{\hdampFootnote}{%
The $h_\text{damp}$ parameter is a resummation damping factor and one of the parameters that controls the matching of \textsc{Powheg} matrix elements to the parton shower and thus effectively regulates the high-$p_T$ radiation against which the \ttbar system recoils.}

The \ttbar events are generated using the \textsc{PowhegBox} \cite{powheg2004, powheg2007, powheg2007_2, powheg2010} \textsc{v2} generator at next-to-leading order with the NNPDF3.0NLO \cite{Ball:2014uwa} set of parton distribution functions (PDFs). The $h_\text{damp}$ parameter\footnote{\hdampFootnote} is set to 1.5 times the mass of the top-quark ($m_\text{top}$)~\cite{ATL-PHYS-PUB-2016-020}, with $m_\text{top} = \SI{172.5}{\GeV}$. 
The events are interfaced to \textsc{Pythia}~8.230~\cite{Sjostrand:2014zea} to model the parton shower, hadronisation, and underlying event, with parameters set according to the A14 tune \cite{ATL-PHYS-PUB-2014-021} and using the NNPDF2.3LO set of PDFs \cite{Ball:2012cx}. 
\Zprime events are generated with \textsc{Pythia} 8.2.12 with the same tune and PDF set.
The decays of \bchadrons are performed by \textsc{EvtGen} v1.6.0 \cite{Lange:2001uf}.
Particles are passed through the ATLAS detector simulation \cite{SOFT-2010-01} based on GEANT4 \cite{Agostinelli:2002hh}.


\subsection{Model Inputs}\label{sec:fake_mva_model_inputs}

%\newcommand{\ipdefsfootnote}{%
%Impact parameter significances are defined as the IP divided by its corresponding uncertainty, $\dzerosig = d_0 / \dzerouncert$ and $\zzerosig = z_0 / \zzerouncert$.
%Track IP significances are lifetime signed according to the track's direction with respect to the jet axis and the primary vertex \cite{PERF-2012-04}.
%}

The fake track MVA is given two jet variables and 20 tracking related variables for each track fed into the network.
The jet transverse momentum and signed pseudorapidity constitute the jet-level inputs, with the track-level inputs listed in \cref{tab:fake_mva_track_inputs}.
The track parameters and hit pattern are key indicators of whether or not a track is fake.
The FracRank variable is the ordered index of the track divided by the total number of tracks in the event.
The ambiguity solver processes track candidates iteratively (see \cref{sec:track_reco}), and the order in which tracks are accepted is preserved.
Tracks which do not require cleaning (i.e. the removal of suspect shared hits) are likely to be accepted earlier on.
Hence the FracRank variable gives an indication of how easy it was for the track to be reconstructed.

\begin{table}[!htbp]
  \footnotesize\centering
  \setlength{\tabcolsep}{0.5em} % for the horizontal padding
  \begin{tabular}{ll}
    \toprule\hline
    \textbf{Jet Input} & \textbf{Description} \\
    \hline
    $\pt$ & Jet transverse momentum \\
    $\eta$ & Signed jet pseudorapidity \\
    \toprule
    \textbf{Track Input} & \textbf{Description} \\
    \hline
    $\pt$ & Track transverse momentum \\
    $\DeltaR$ & Angular distance between the track and jet \\
    $d_0$  & Closest distance from the track to the PV in the longitudinal plane \\
    $z_0$  & Closest distance from the track to the PV in the transverse plane \\
    nIBLHits   & Number of IBL hits \\
    nPixHits   & Number of pixel hits \\
    nSCTHits   & Number of SCT hits \\
    nTRTHits   & Number of TRT hits \\
    nBLHits    & Number of B-layer hits \\
    nIBLShared & Number of shared IBL hits \\
    nIBLSplit  & Number of split IBL hits \\
    nPixShared & Number of shared pixel hits \\
    nPixSplit  & Number of split pixel hits \\
    nSCTShared & Number of shared SCT hits \\
    $r_{\textnormal{first}}$      & Radius of first hit \\
    nDOF   & Number of degrees of freedom on the track \\
    FracRank & Ambiguity solver ordering variable \\
    \hline\bottomrule
  \end{tabular}
  \caption{
    Input features to the fake track classification NN.
    Basic jet kinematics, along with information about the reconstructed track parameters and constituent hits are used.
    Shared hits, are hits used on multiple tracks which have not been classified as split by the cluster-splitting neural networks~\cite{PERF-2015-08}, while split hits are hits used on multiple tracks which have been identified as merged.
  }
  \label{tab:fake_mva_track_inputs}
\end{table}

Track selection follows the loose selection described in \rcite{ATL-PHYS-PUB-2020-014} and outlined in \cref{tab:fake_track_mva_selections}, which was found to improve the flavour tagging performance compared to previous tighter selections, whilst ensuring good resolution of tracks and a low fake rate \cite{PERF-2015-08}.
Inputs are scaled to have a central value of zero and a variance of unity before training and evaluation.

\begin{table}[!htbp]
  \footnotesize\centering
  \setlength{\tabcolsep}{0.5em} % for the horizontal padding
  \begin{tabular}{ll}
    \toprule\hline
    \textbf{Parameter} & \textbf{Selection} \\
    \hline
    $\pt$                & $> 500$ MeV \\
    $|d_0|$              & $< 3.5$ mm \\
    $|z_0 \sin\theta|$   & $< 5$ mm \\
    Silicon hits         & $\ge 8$ \\
    Shared silicon hits  & $< 2$ \\
    Silicon holes        & $< 3$ \\
    Pixel holes          & $< 2$ \\
    \hline\bottomrule
  \end{tabular}
  \caption{
    Quality selections applied to tracks,
    where $d_0$ is the transverse IP of the track, $z_0$ is the longitudinal IP with respect to the PV and $\theta$ is the track polar angle.
    Shared hits are hits used on multiple tracks which have not been classified as split by the cluster-splitting neural networks~\cite{PERF-2015-08}.
    Shared hits on pixel layers are given a weight of 1, while shared hits in the SCT are given a weight of 0.5.
    A hole is a missing hit, where one is expected, on a layer between two other hits on a track.
    }
  \vspace{4mm}
  \label{tab:fake_track_mva_selections}
\end{table}




\subsection{Results}\label{sec:fake_track_mva_results}


Performance of the fake track classification tool was run on $1$ million tracks tracks in jets in the combined \ttbar and \Zprime samples.
The continuous scalar output from the NN model is interpreted as the probability that a given track is a good track (i.e. not fake).
\cref{fig:track_classifier_output_roc} shows the performance of the fake track classification MVA. The signal and background classes are well separated in the output of the tool.
Also shown in a receiver operating characteristic (ROC) curve, which plots the rate of true positives against the rate of false positives over a scan of cut points on the NN output ranging from zero to one.
The area under the curve (AUC) gives a summary of the aggregate classification power of the model.
The fake track classification tool achieves an AUC of $0.935$ for all tracks. Considering only tracks from \bhadron decays, this value drops slightly to $0.928$. 

\begin{figure}[!htbp]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
      \centering
      \includegraphics[width=\textwidth]{chapters/track_classifier/figs/track_classifier_ouput.pdf}
  \end{subfigure}
  \quad
  \begin{subfigure}[b]{0.48\textwidth}
      \centering
      \includegraphics[width=\textwidth]{chapters/track_classifier/figs/track_classifier_roc.pdf}
  \end{subfigure}
  \caption{
    (left) Normalised histogram of the model output separated for good and fake tracks, and further separated by those tracks which are from the decay of a \bhadron.
    (right) The ROC curve for all tracks (solid line) and tracks from the decay of a \bhadron (dashed line).
  }
  \label{fig:track_classifier_output_roc}
\end{figure}

Good and fake track efficiencies at two different NN output cut points are shown in \cref{tab:fake_track_mva_effs}.
The results demonstrate that the tool is effective in retaining \pct{98.8} of good tracks, while correctly identifying (and therefore enabling the removal of) \pct{45.6} of fake tracks.
\cref{tab:fake_track_mva_effs} also shows that a significant amount of tracks which are labelled as both fake and from the decay of a \bhadron are also removed.

\begin{table}[!htbp]
  \footnotesize\centering
  \setlength{\tabcolsep}{0.5em} % for the horizontal padding
  \begin{tabular}{ccccc}
      \toprule\hline
      \multirow{2}{2cm}{MVA Output Cut} & \multicolumn{2}{c}{Good Track Efficiency} & \multicolumn{2}{c}{Fake Track Efficiency} \\
      & All & From $b$ & All & From $b$ \\
      \hline
      0.06 & \pct{98.8} & \pct{98.9} & \pct{45.6} & \pct{39.8} \\
      0.12 & \pct{97.3} & \pct{97.5} & \pct{59.4} & \pct{53.6} \\
      \hline\bottomrule
  \end{tabular}
  \caption{
    Good and fake track selection efficiencies for the combined \ttbar and \Zprime samples.
    Two working points are defined, cutting on the NN output at $0.06$ and $0.12$.
    The continuous output of the model allows for the tuning of good and fake track identification efficiencies.
  }
  \label{tab:fake_track_mva_effs}
\end{table}

After initial tests and investigation, it was found that fake tracks which were the result of \bhadron decays actually aided \btagging performance.
The application of a single tool which removed all fake tracks was no longer optimal.
A second tool was trained in the same manner of the first, this one was designed to distinguish between those tracks which were from the decay of a \bhadron and those which were not.
A 2-dimensional cut was then used to only reject those tracks that had a high probability of being fake, and also a low probability of being a \bhadron decay track.
The \ljet efficiency of SV1 shows an improvement when using the combined tools to remove fake tracks that are not from a \bhadron decay, as shown in \cref{fig:track_classifier_btag_effects}

\begin{figure}[!htbp]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
      \centering
      \includegraphics[width=\textwidth]{chapters/track_classifier/figs/track_classifier_result_lowpt.pdf}
  \end{subfigure}
  \quad
  \begin{subfigure}[b]{0.48\textwidth}
      \centering
      \includegraphics[width=\textwidth]{chapters/track_classifier/figs/track_classifier_result_hipt.pdf}
  \end{subfigure}
  \caption{
    The effect of applying the fake track identification algorithm alongside the \bhadron decay track identification on the jet tagging performance of SV1 for jets with $\SI{250}{\GeV} < \pt < \SI{400}{\GeV}$ (left) and for jets with $\SI{400}{\GeV} < \pt < \SI{1}{\TeV}$ (right).
    The nominal SV1 \lrej (black) is compared to two working points of fake track removal (orange and red).
    Removal of fake tracks based on truth information is shown by the green curves.
  }
  \label{fig:track_classifier_btag_effects}
\end{figure}

\todo{also show plots for JF?}


\section{Conclusion}\label{sec:fake_track_mva_conclusion}

Fake tracks, which are prevalent in the core of high \pt jets, are shown to have an adverse impact on \btagging performance.
A ML tool to identify fake tracks has been developed, which can be used to limit the number of fake tracks being inputted to downstream \btagging algorithms.
It was found that, since many \bhadron decay tracks are poorly reconstructed and thus marked as fake, it was necessary also to train a second algorithm to detect \bhadron decay tracks so that the removal of these tracks could be avoided.
Removing fake and non-$b$ decay tracks in this way was found to improve the tagging efficiency of SV1 and JetFitter at high transverse momentum.

While removing tracks prior to their input to the low level tagging algorithms is beneficial, a more performant alternative would be to keep these tracks but label them as being fake or poorly reconstructed, and allow the tagging algorithms to take this into consideration, potentially still making use of some of the information.
%A more advanced approach than detecting and removing fake tracks is to attempt to determine whether a track is good or fake, but allow any downstream tagging algorithms to use this information when coming to a descision about wether to tag a jet, rather than removing the track as an input.

%These fake or poorly reconstructed tracks could also be remove in other places\todo{keep?}

These tools, which identify the origin of a given track, have other potential uses.
One application is to isolate a relatively pure sample of fake tracks which can be used to estimate the fake track rate in data, which would be useful for producing the recommendations for tracking systematic uncertainties.
Another application would be to use the \bhadron track identification tool to improve the track-to-jet association.

The approach here works on a track-by-track basis, but a more sophisticated approach would consider the correlations between the tracks inside a jet, as shown in \cref{chap:gnn_tagger}.

Also left for future work is to simultaneously train a single tool which discriminates between all the truth origins listed in \cref{tab:truth_origins}.
Such a tool would be useful as a general purpose multiclass classifier.